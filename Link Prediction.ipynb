{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gavin/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "from linkpred import *\n",
    "from dataset import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.style as style \n",
    "style.use('seaborn-paper')\n",
    "%matplotlib inline\n",
    "\n",
    "fontsize = 12\n",
    "plt.rcParams.update({\n",
    "    'font.size': fontsize, \n",
    "    'axes.labelsize': fontsize, \n",
    "    'legend.fontsize': fontsize,\n",
    "    'xtick.labelsize': fontsize,\n",
    "    'ytick.labelsize': fontsize,\n",
    "    'axes.titlesize': fontsize\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fec8c0adf70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set random seeds\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device =', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>worker</th>\n",
       "      <th>relationship</th>\n",
       "      <th>household_income</th>\n",
       "      <th>household_size</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>household_vehicles</th>\n",
       "      <th>household_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2509159</td>\n",
       "      <td>2201175</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>97201</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2509160</td>\n",
       "      <td>2201175</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>97201</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2509161</td>\n",
       "      <td>2201175</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>97201</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2509162</td>\n",
       "      <td>2201176</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>97201</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2509163</td>\n",
       "      <td>2201176</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>97201</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  household_id  age  gender  worker  relationship  \\\n",
       "0    2509159       2201175   42       1       1             1   \n",
       "1    2509160       2201175   43       2       1             1   \n",
       "2    2509161       2201175   17       1       2             2   \n",
       "3    2509162       2201176   41       1       1             1   \n",
       "4    2509163       2201176   11       1       2             2   \n",
       "\n",
       "   household_income  household_size  zipcode  household_vehicles  \\\n",
       "0                13               3    97201                   3   \n",
       "1                13               3    97201                   3   \n",
       "2                13               3    97201                   3   \n",
       "3                11               2    97201                   3   \n",
       "4                11               2    97201                   3   \n",
       "\n",
       "   household_workers  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  1  \n",
       "4                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_attributes = pd.read_csv('data/NDSSL data/raw/node_attributes.csv')\n",
    "node_attributes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "{'x': None, 'edge_index': tensor([[      0,       0,       1,  ..., 1486224, 1378614, 1556530],\n",
      "        [      1,       2,       2,  ..., 1601329, 1601329, 1601329]]), 'edge_attr': None, 'y': None, 'pos': None, 'norm': None, 'face': None, 'edge_weight': tensor([10.9161, 12.7494, 12.5828,  ...,  0.0497,  0.1667,  0.1667])}\n",
      "Done!\n",
      "{'x': None, 'edge_index': tensor([[      0,       0,       1,  ..., 1486224, 1378614, 1556530],\n",
      "        [      1,       2,       2,  ..., 1601329, 1601329, 1601329]]), 'edge_attr': None, 'y': None, 'pos': None, 'norm': None, 'face': None, 'edge_weight': tensor([10.9161, 12.7494, 12.5828,  ...,  0.0497,  0.1667,  0.1667])}\n"
     ]
    }
   ],
   "source": [
    "## remove old processed files\n",
    "import os, shutil\n",
    "if os.path.exists('data/NDSSL data/processed'):\n",
    "    shutil.rmtree('data/NDSSL data/processed')\n",
    "\n",
    "dataset = load_dataset(dataset_name='NDSSL')\n",
    "data = dataset[0]\n",
    "dataset.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train edges: 19388850\n",
      "number of train edges: 19570466\n",
      "number of train edges: 3936\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_big(data, val_ratio=0.5, test_ratio=0.0001)\n",
    "\n",
    "print('number of train edges: %i' %data.train_pos_edge_index.shape[1])\n",
    "print('number of train edges: %i' %data.val_pos_edge_index.shape[1])\n",
    "print('number of train edges: %i' %data.test_pos_edge_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1601330, 143])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_columns = ['age', 'gender', 'worker', 'relationship', 'household_income', 'household_size', 'zipcode', 'household_vehicles', 'household_workers']\n",
    "data.x = dataframe2onehot(node_attributes[data_columns], node_attributes)\n",
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(x=data.x, edge_index=data.train_pos_edge_index, y=data.y)\n",
    "row, col = train_data.edge_index\n",
    "train_data.edge_attr = 1. / degree(col, train_data.num_nodes)[col]  # Norm by in-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = Data(x=data.x, edge_index=data.val_pos_edge_index, y=data.y)\n",
    "row, col = val_data.edge_index\n",
    "val_data.edge_attr = 1. / degree(col, val_data.num_nodes)[col]  # Norm by in-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Data(x=data.x, edge_index=data.test_pos_edge_index, y=data.y)\n",
    "row, col = test_data.edge_index\n",
    "test_data.edge_attr = 1. / degree(col, test_data.num_nodes)[col]  # Norm by in-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 30\n",
    "batch_size = 1000\n",
    "num_steps = 10\n",
    "sample_coverage = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute GraphSAINT normalization: : 37091443it [00:38, 975916.50it/s]                            \n"
     ]
    }
   ],
   "source": [
    "train_loader = GraphSAINTRandomWalkSampler(train_data, batch_size=batch_size, walk_length=walk_length,\n",
    "                                     num_steps=num_steps, sample_coverage=sample_coverage,\n",
    "                                     save_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute GraphSAINT normalization: : 36043436it [00:34, 1039014.43it/s]                            \n"
     ]
    }
   ],
   "source": [
    "val_loader = GraphSAINTRandomWalkSampler(val_data, batch_size=batch_size, walk_length=walk_length,\n",
    "                                     num_steps=num_steps, sample_coverage=sample_coverage,\n",
    "                                     save_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_loader = GraphSAINTRandomWalkSampler(test_data, batch_size=batch_size, walk_length=walk_length,\n",
    "                                     num_steps=num_steps, sample_coverage=sample_coverage,\n",
    "                                     save_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(num_node_features=train_data.x.shape[1], hidden_channels=256, embed_dim=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    model.set_aggr('mean')\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr) #batch.edge_norm * batch.edge_attr\n",
    "        loss = model.recon_loss(out, batch.edge_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_examples += batch.num_edges\n",
    "    return total_loss/total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluator(loader):\n",
    "    model.eval()\n",
    "    model.set_aggr('mean')\n",
    "    \n",
    "    y_target = torch.empty(0)\n",
    "    y_pred = torch.empty(0)\n",
    "    total_loss = total_examples = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        total_loss += model.recon_loss(out, batch.edge_index).item()\n",
    "        total_examples += batch.num_edges\n",
    "        \n",
    "        test_results = model.test(out, batch.edge_index, negative_sampling(batch.edge_index, out.size(0)))\n",
    "        y_target = torch.cat((y_target, test_results[0]), 0)\n",
    "        y_pred = torch.cat((y_pred, test_results[1]), 0)\n",
    "        \n",
    "    y_target = y_target.numpy()\n",
    "    y_pred = y_pred.numpy()\n",
    "    \n",
    "    return total_loss/total_examples, y_target, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1||Train Loss: 1.891||Val Loss: 1.784||Val AUC: 0.528||Val AP: 0.524\n",
      "Epoch: 2||Train Loss: 1.816||Val Loss: 1.767||Val AUC: 0.590||Val AP: 0.566\n",
      "Epoch: 3||Train Loss: 1.803||Val Loss: 1.762||Val AUC: 0.626||Val AP: 0.590\n",
      "Epoch: 4||Train Loss: 1.796||Val Loss: 1.758||Val AUC: 0.628||Val AP: 0.593\n",
      "Epoch: 5||Train Loss: 1.788||Val Loss: 1.749||Val AUC: 0.631||Val AP: 0.593\n",
      "Epoch: 6||Train Loss: 1.781||Val Loss: 1.747||Val AUC: 0.641||Val AP: 0.605\n",
      "Epoch: 7||Train Loss: 1.774||Val Loss: 1.737||Val AUC: 0.644||Val AP: 0.606\n",
      "Epoch: 8||Train Loss: 1.768||Val Loss: 1.734||Val AUC: 0.646||Val AP: 0.609\n",
      "Epoch: 9||Train Loss: 1.761||Val Loss: 1.732||Val AUC: 0.652||Val AP: 0.617\n",
      "Epoch: 10||Train Loss: 1.754||Val Loss: 1.720||Val AUC: 0.656||Val AP: 0.619\n",
      "Epoch: 11||Train Loss: 1.747||Val Loss: 1.720||Val AUC: 0.662||Val AP: 0.626\n",
      "Epoch: 12||Train Loss: 1.739||Val Loss: 1.710||Val AUC: 0.669||Val AP: 0.633\n",
      "Epoch: 13||Train Loss: 1.733||Val Loss: 1.702||Val AUC: 0.675||Val AP: 0.637\n",
      "Epoch: 14||Train Loss: 1.725||Val Loss: 1.697||Val AUC: 0.682||Val AP: 0.644\n",
      "Epoch: 15||Train Loss: 1.718||Val Loss: 1.684||Val AUC: 0.687||Val AP: 0.647\n",
      "Epoch: 16||Train Loss: 1.711||Val Loss: 1.672||Val AUC: 0.692||Val AP: 0.650\n",
      "Epoch: 17||Train Loss: 1.704||Val Loss: 1.670||Val AUC: 0.697||Val AP: 0.657\n",
      "Epoch: 18||Train Loss: 1.696||Val Loss: 1.664||Val AUC: 0.702||Val AP: 0.664\n",
      "Epoch: 19||Train Loss: 1.687||Val Loss: 1.658||Val AUC: 0.709||Val AP: 0.671\n",
      "Epoch: 20||Train Loss: 1.679||Val Loss: 1.651||Val AUC: 0.716||Val AP: 0.679\n",
      "Epoch: 21||Train Loss: 1.671||Val Loss: 1.634||Val AUC: 0.718||Val AP: 0.678\n",
      "Epoch: 22||Train Loss: 1.663||Val Loss: 1.671||Val AUC: 0.722||Val AP: 0.692\n",
      "Epoch: 23||Train Loss: 1.656||Val Loss: 1.621||Val AUC: 0.726||Val AP: 0.688\n",
      "Epoch: 24||Train Loss: 1.646||Val Loss: 1.614||Val AUC: 0.732||Val AP: 0.695\n",
      "Epoch: 25||Train Loss: 1.640||Val Loss: 1.604||Val AUC: 0.741||Val AP: 0.703\n",
      "Epoch: 26||Train Loss: 1.635||Val Loss: 1.610||Val AUC: 0.741||Val AP: 0.707\n",
      "Epoch: 27||Train Loss: 1.625||Val Loss: 1.622||Val AUC: 0.742||Val AP: 0.714\n",
      "Epoch: 28||Train Loss: 1.618||Val Loss: 1.592||Val AUC: 0.744||Val AP: 0.710\n",
      "Epoch: 29||Train Loss: 1.613||Val Loss: 1.593||Val AUC: 0.750||Val AP: 0.719\n",
      "Epoch: 30||Train Loss: 1.605||Val Loss: 1.606||Val AUC: 0.749||Val AP: 0.720\n",
      "Epoch: 31||Train Loss: 1.599||Val Loss: 1.595||Val AUC: 0.754||Val AP: 0.725\n",
      "Epoch: 32||Train Loss: 1.596||Val Loss: 1.600||Val AUC: 0.754||Val AP: 0.725\n",
      "Epoch: 33||Train Loss: 1.590||Val Loss: 1.562||Val AUC: 0.757||Val AP: 0.724\n",
      "Epoch: 34||Train Loss: 1.581||Val Loss: 1.576||Val AUC: 0.761||Val AP: 0.731\n",
      "Epoch: 35||Train Loss: 1.573||Val Loss: 1.553||Val AUC: 0.765||Val AP: 0.733\n",
      "Epoch: 36||Train Loss: 1.566||Val Loss: 1.553||Val AUC: 0.765||Val AP: 0.734\n",
      "Epoch: 37||Train Loss: 1.560||Val Loss: 1.540||Val AUC: 0.767||Val AP: 0.736\n",
      "Epoch: 38||Train Loss: 1.555||Val Loss: 1.573||Val AUC: 0.768||Val AP: 0.737\n",
      "Epoch: 39||Train Loss: 1.549||Val Loss: 1.543||Val AUC: 0.771||Val AP: 0.740\n",
      "Epoch: 40||Train Loss: 1.541||Val Loss: 1.535||Val AUC: 0.773||Val AP: 0.743\n",
      "Epoch: 41||Train Loss: 1.536||Val Loss: 1.509||Val AUC: 0.775||Val AP: 0.742\n",
      "Epoch: 42||Train Loss: 1.534||Val Loss: 1.523||Val AUC: 0.773||Val AP: 0.741\n",
      "Epoch: 43||Train Loss: 1.526||Val Loss: 1.509||Val AUC: 0.779||Val AP: 0.748\n",
      "Epoch: 44||Train Loss: 1.521||Val Loss: 1.503||Val AUC: 0.781||Val AP: 0.749\n",
      "Epoch: 45||Train Loss: 1.516||Val Loss: 1.522||Val AUC: 0.782||Val AP: 0.751\n",
      "Epoch: 46||Train Loss: 1.510||Val Loss: 1.493||Val AUC: 0.785||Val AP: 0.753\n",
      "Epoch: 47||Train Loss: 1.503||Val Loss: 1.487||Val AUC: 0.783||Val AP: 0.751\n",
      "Epoch: 48||Train Loss: 1.501||Val Loss: 1.496||Val AUC: 0.788||Val AP: 0.756\n",
      "Epoch: 49||Train Loss: 1.490||Val Loss: 1.471||Val AUC: 0.789||Val AP: 0.756\n",
      "Epoch: 50||Train Loss: 1.489||Val Loss: 1.479||Val AUC: 0.791||Val AP: 0.759\n",
      "Epoch: 51||Train Loss: 1.483||Val Loss: 1.456||Val AUC: 0.794||Val AP: 0.762\n",
      "Epoch: 52||Train Loss: 1.476||Val Loss: 1.478||Val AUC: 0.791||Val AP: 0.759\n",
      "Epoch: 53||Train Loss: 1.469||Val Loss: 1.459||Val AUC: 0.797||Val AP: 0.765\n",
      "Epoch: 54||Train Loss: 1.461||Val Loss: 1.460||Val AUC: 0.797||Val AP: 0.767\n",
      "Epoch: 55||Train Loss: 1.454||Val Loss: 1.446||Val AUC: 0.800||Val AP: 0.769\n",
      "Epoch: 56||Train Loss: 1.453||Val Loss: 1.461||Val AUC: 0.799||Val AP: 0.769\n",
      "Epoch: 57||Train Loss: 1.446||Val Loss: 1.450||Val AUC: 0.803||Val AP: 0.774\n",
      "Epoch: 58||Train Loss: 1.442||Val Loss: 1.443||Val AUC: 0.804||Val AP: 0.775\n",
      "Epoch: 59||Train Loss: 1.435||Val Loss: 1.445||Val AUC: 0.806||Val AP: 0.776\n",
      "Epoch: 60||Train Loss: 1.431||Val Loss: 1.420||Val AUC: 0.808||Val AP: 0.778\n",
      "Epoch: 61||Train Loss: 1.423||Val Loss: 1.431||Val AUC: 0.811||Val AP: 0.781\n",
      "Epoch: 62||Train Loss: 1.417||Val Loss: 1.406||Val AUC: 0.812||Val AP: 0.783\n",
      "Epoch: 63||Train Loss: 1.414||Val Loss: 1.406||Val AUC: 0.817||Val AP: 0.790\n",
      "Epoch: 64||Train Loss: 1.407||Val Loss: 1.441||Val AUC: 0.814||Val AP: 0.786\n",
      "Epoch: 65||Train Loss: 1.400||Val Loss: 1.413||Val AUC: 0.819||Val AP: 0.794\n",
      "Epoch: 66||Train Loss: 1.395||Val Loss: 1.406||Val AUC: 0.819||Val AP: 0.794\n",
      "Epoch: 67||Train Loss: 1.392||Val Loss: 1.404||Val AUC: 0.823||Val AP: 0.799\n",
      "Epoch: 68||Train Loss: 1.387||Val Loss: 1.425||Val AUC: 0.821||Val AP: 0.794\n",
      "Epoch: 69||Train Loss: 1.381||Val Loss: 1.402||Val AUC: 0.824||Val AP: 0.797\n",
      "Epoch: 70||Train Loss: 1.372||Val Loss: 1.396||Val AUC: 0.824||Val AP: 0.797\n",
      "Epoch: 71||Train Loss: 1.369||Val Loss: 1.371||Val AUC: 0.829||Val AP: 0.803\n",
      "Epoch: 72||Train Loss: 1.364||Val Loss: 1.379||Val AUC: 0.829||Val AP: 0.803\n",
      "Epoch: 73||Train Loss: 1.359||Val Loss: 1.391||Val AUC: 0.828||Val AP: 0.803\n",
      "Epoch: 74||Train Loss: 1.354||Val Loss: 1.376||Val AUC: 0.832||Val AP: 0.808\n",
      "Epoch: 75||Train Loss: 1.348||Val Loss: 1.354||Val AUC: 0.837||Val AP: 0.814\n",
      "Epoch: 76||Train Loss: 1.344||Val Loss: 1.380||Val AUC: 0.835||Val AP: 0.811\n",
      "Epoch: 77||Train Loss: 1.340||Val Loss: 1.333||Val AUC: 0.838||Val AP: 0.816\n",
      "Epoch: 78||Train Loss: 1.333||Val Loss: 1.368||Val AUC: 0.839||Val AP: 0.819\n",
      "Epoch: 79||Train Loss: 1.329||Val Loss: 1.360||Val AUC: 0.839||Val AP: 0.814\n",
      "Epoch: 80||Train Loss: 1.325||Val Loss: 1.366||Val AUC: 0.837||Val AP: 0.813\n",
      "Epoch: 81||Train Loss: 1.321||Val Loss: 1.365||Val AUC: 0.840||Val AP: 0.817\n",
      "Epoch: 82||Train Loss: 1.311||Val Loss: 1.351||Val AUC: 0.842||Val AP: 0.820\n",
      "Epoch: 83||Train Loss: 1.305||Val Loss: 1.327||Val AUC: 0.844||Val AP: 0.823\n",
      "Epoch: 84||Train Loss: 1.301||Val Loss: 1.313||Val AUC: 0.846||Val AP: 0.827\n",
      "Epoch: 85||Train Loss: 1.294||Val Loss: 1.310||Val AUC: 0.848||Val AP: 0.828\n",
      "Epoch: 86||Train Loss: 1.293||Val Loss: 1.303||Val AUC: 0.850||Val AP: 0.829\n",
      "Epoch: 87||Train Loss: 1.288||Val Loss: 1.289||Val AUC: 0.851||Val AP: 0.829\n",
      "Epoch: 88||Train Loss: 1.283||Val Loss: 1.330||Val AUC: 0.850||Val AP: 0.834\n",
      "Epoch: 89||Train Loss: 1.277||Val Loss: 1.317||Val AUC: 0.852||Val AP: 0.835\n",
      "Epoch: 90||Train Loss: 1.273||Val Loss: 1.302||Val AUC: 0.853||Val AP: 0.836\n",
      "Epoch: 91||Train Loss: 1.266||Val Loss: 1.343||Val AUC: 0.850||Val AP: 0.833\n",
      "Epoch: 92||Train Loss: 1.262||Val Loss: 1.270||Val AUC: 0.857||Val AP: 0.841\n",
      "Epoch: 93||Train Loss: 1.259||Val Loss: 1.277||Val AUC: 0.859||Val AP: 0.843\n",
      "Epoch: 94||Train Loss: 1.253||Val Loss: 1.272||Val AUC: 0.859||Val AP: 0.843\n",
      "Epoch: 95||Train Loss: 1.248||Val Loss: 1.292||Val AUC: 0.858||Val AP: 0.842\n",
      "Epoch: 96||Train Loss: 1.241||Val Loss: 1.291||Val AUC: 0.858||Val AP: 0.845\n",
      "Epoch: 97||Train Loss: 1.239||Val Loss: 1.261||Val AUC: 0.863||Val AP: 0.849\n",
      "Epoch: 98||Train Loss: 1.235||Val Loss: 1.299||Val AUC: 0.860||Val AP: 0.846\n",
      "Epoch: 99||Train Loss: 1.232||Val Loss: 1.262||Val AUC: 0.862||Val AP: 0.847\n",
      "Epoch: 100||Train Loss: 1.226||Val Loss: 1.257||Val AUC: 0.865||Val AP: 0.848\n",
      "Epoch: 101||Train Loss: 1.224||Val Loss: 1.250||Val AUC: 0.865||Val AP: 0.851\n",
      "Epoch: 102||Train Loss: 1.217||Val Loss: 1.248||Val AUC: 0.866||Val AP: 0.852\n",
      "Epoch: 103||Train Loss: 1.213||Val Loss: 1.254||Val AUC: 0.865||Val AP: 0.853\n",
      "Epoch: 104||Train Loss: 1.208||Val Loss: 1.236||Val AUC: 0.868||Val AP: 0.855\n",
      "Epoch: 105||Train Loss: 1.206||Val Loss: 1.244||Val AUC: 0.868||Val AP: 0.855\n",
      "Epoch: 106||Train Loss: 1.200||Val Loss: 1.237||Val AUC: 0.870||Val AP: 0.856\n",
      "Epoch: 107||Train Loss: 1.195||Val Loss: 1.236||Val AUC: 0.868||Val AP: 0.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108||Train Loss: 1.190||Val Loss: 1.236||Val AUC: 0.872||Val AP: 0.858\n",
      "Epoch: 109||Train Loss: 1.189||Val Loss: 1.218||Val AUC: 0.871||Val AP: 0.857\n",
      "Epoch: 110||Train Loss: 1.183||Val Loss: 1.201||Val AUC: 0.875||Val AP: 0.863\n",
      "Epoch: 111||Train Loss: 1.180||Val Loss: 1.219||Val AUC: 0.872||Val AP: 0.859\n",
      "Epoch: 112||Train Loss: 1.173||Val Loss: 1.209||Val AUC: 0.873||Val AP: 0.862\n",
      "Epoch: 113||Train Loss: 1.172||Val Loss: 1.221||Val AUC: 0.873||Val AP: 0.863\n",
      "Epoch: 114||Train Loss: 1.168||Val Loss: 1.209||Val AUC: 0.874||Val AP: 0.860\n",
      "Epoch: 115||Train Loss: 1.164||Val Loss: 1.196||Val AUC: 0.876||Val AP: 0.866\n",
      "Epoch: 116||Train Loss: 1.161||Val Loss: 1.189||Val AUC: 0.878||Val AP: 0.867\n",
      "Epoch: 117||Train Loss: 1.158||Val Loss: 1.191||Val AUC: 0.878||Val AP: 0.867\n",
      "Epoch: 118||Train Loss: 1.151||Val Loss: 1.206||Val AUC: 0.877||Val AP: 0.867\n",
      "Epoch: 119||Train Loss: 1.150||Val Loss: 1.189||Val AUC: 0.879||Val AP: 0.868\n",
      "Epoch: 120||Train Loss: 1.144||Val Loss: 1.182||Val AUC: 0.881||Val AP: 0.870\n",
      "Epoch: 121||Train Loss: 1.143||Val Loss: 1.202||Val AUC: 0.879||Val AP: 0.869\n",
      "Epoch: 122||Train Loss: 1.139||Val Loss: 1.175||Val AUC: 0.880||Val AP: 0.871\n",
      "Epoch: 123||Train Loss: 1.135||Val Loss: 1.169||Val AUC: 0.882||Val AP: 0.872\n",
      "Epoch: 124||Train Loss: 1.130||Val Loss: 1.140||Val AUC: 0.884||Val AP: 0.875\n",
      "Epoch: 125||Train Loss: 1.130||Val Loss: 1.165||Val AUC: 0.882||Val AP: 0.870\n",
      "Epoch: 126||Train Loss: 1.120||Val Loss: 1.157||Val AUC: 0.883||Val AP: 0.874\n",
      "Epoch: 127||Train Loss: 1.116||Val Loss: 1.167||Val AUC: 0.883||Val AP: 0.875\n",
      "Epoch: 128||Train Loss: 1.113||Val Loss: 1.150||Val AUC: 0.885||Val AP: 0.876\n",
      "Epoch: 129||Train Loss: 1.110||Val Loss: 1.153||Val AUC: 0.886||Val AP: 0.876\n",
      "Epoch: 130||Train Loss: 1.107||Val Loss: 1.147||Val AUC: 0.887||Val AP: 0.878\n",
      "Epoch: 131||Train Loss: 1.103||Val Loss: 1.151||Val AUC: 0.884||Val AP: 0.875\n",
      "Epoch: 132||Train Loss: 1.099||Val Loss: 1.126||Val AUC: 0.888||Val AP: 0.879\n",
      "Epoch: 133||Train Loss: 1.096||Val Loss: 1.131||Val AUC: 0.888||Val AP: 0.880\n",
      "Epoch: 134||Train Loss: 1.095||Val Loss: 1.125||Val AUC: 0.888||Val AP: 0.879\n",
      "Epoch: 135||Train Loss: 1.092||Val Loss: 1.129||Val AUC: 0.886||Val AP: 0.877\n",
      "Epoch: 136||Train Loss: 1.091||Val Loss: 1.113||Val AUC: 0.887||Val AP: 0.879\n",
      "Epoch: 137||Train Loss: 1.084||Val Loss: 1.128||Val AUC: 0.887||Val AP: 0.878\n",
      "Epoch: 138||Train Loss: 1.082||Val Loss: 1.136||Val AUC: 0.888||Val AP: 0.879\n",
      "Epoch: 139||Train Loss: 1.078||Val Loss: 1.137||Val AUC: 0.888||Val AP: 0.880\n",
      "Epoch: 140||Train Loss: 1.076||Val Loss: 1.135||Val AUC: 0.889||Val AP: 0.882\n",
      "Epoch: 141||Train Loss: 1.073||Val Loss: 1.104||Val AUC: 0.891||Val AP: 0.882\n",
      "Epoch: 142||Train Loss: 1.069||Val Loss: 1.102||Val AUC: 0.891||Val AP: 0.881\n",
      "Epoch: 143||Train Loss: 1.065||Val Loss: 1.111||Val AUC: 0.892||Val AP: 0.883\n",
      "Epoch: 144||Train Loss: 1.060||Val Loss: 1.104||Val AUC: 0.891||Val AP: 0.883\n",
      "Epoch: 145||Train Loss: 1.057||Val Loss: 1.120||Val AUC: 0.892||Val AP: 0.883\n",
      "Epoch: 146||Train Loss: 1.054||Val Loss: 1.087||Val AUC: 0.894||Val AP: 0.887\n",
      "Epoch: 147||Train Loss: 1.052||Val Loss: 1.104||Val AUC: 0.893||Val AP: 0.886\n",
      "Epoch: 148||Train Loss: 1.048||Val Loss: 1.095||Val AUC: 0.895||Val AP: 0.887\n",
      "Epoch: 149||Train Loss: 1.046||Val Loss: 1.104||Val AUC: 0.892||Val AP: 0.885\n",
      "Epoch: 150||Train Loss: 1.041||Val Loss: 1.073||Val AUC: 0.897||Val AP: 0.888\n",
      "Epoch: 151||Train Loss: 1.040||Val Loss: 1.071||Val AUC: 0.896||Val AP: 0.889\n",
      "Epoch: 152||Train Loss: 1.036||Val Loss: 1.088||Val AUC: 0.895||Val AP: 0.887\n",
      "Epoch: 153||Train Loss: 1.035||Val Loss: 1.075||Val AUC: 0.897||Val AP: 0.889\n",
      "Epoch: 154||Train Loss: 1.030||Val Loss: 1.069||Val AUC: 0.898||Val AP: 0.889\n",
      "Epoch: 155||Train Loss: 1.027||Val Loss: 1.072||Val AUC: 0.896||Val AP: 0.889\n",
      "Epoch: 156||Train Loss: 1.025||Val Loss: 1.080||Val AUC: 0.897||Val AP: 0.890\n",
      "Epoch: 157||Train Loss: 1.025||Val Loss: 1.079||Val AUC: 0.897||Val AP: 0.890\n",
      "Epoch: 158||Train Loss: 1.022||Val Loss: 1.058||Val AUC: 0.899||Val AP: 0.891\n",
      "Epoch: 159||Train Loss: 1.017||Val Loss: 1.055||Val AUC: 0.898||Val AP: 0.890\n",
      "Epoch: 160||Train Loss: 1.015||Val Loss: 1.054||Val AUC: 0.898||Val AP: 0.892\n",
      "Epoch: 161||Train Loss: 1.012||Val Loss: 1.070||Val AUC: 0.900||Val AP: 0.893\n",
      "Epoch: 162||Train Loss: 1.006||Val Loss: 1.051||Val AUC: 0.901||Val AP: 0.893\n",
      "Epoch: 163||Train Loss: 1.005||Val Loss: 1.054||Val AUC: 0.899||Val AP: 0.892\n",
      "Epoch: 164||Train Loss: 1.002||Val Loss: 1.048||Val AUC: 0.900||Val AP: 0.893\n",
      "Epoch: 165||Train Loss: 1.000||Val Loss: 1.050||Val AUC: 0.900||Val AP: 0.894\n",
      "Epoch: 166||Train Loss: 0.998||Val Loss: 1.047||Val AUC: 0.902||Val AP: 0.895\n",
      "Epoch: 167||Train Loss: 0.991||Val Loss: 1.048||Val AUC: 0.902||Val AP: 0.895\n",
      "Epoch: 168||Train Loss: 0.990||Val Loss: 1.035||Val AUC: 0.903||Val AP: 0.897\n",
      "Epoch: 169||Train Loss: 0.987||Val Loss: 1.051||Val AUC: 0.902||Val AP: 0.895\n",
      "Epoch: 170||Train Loss: 0.985||Val Loss: 1.024||Val AUC: 0.904||Val AP: 0.897\n",
      "Epoch: 171||Train Loss: 0.981||Val Loss: 1.024||Val AUC: 0.904||Val AP: 0.898\n",
      "Epoch: 172||Train Loss: 0.978||Val Loss: 1.021||Val AUC: 0.905||Val AP: 0.898\n",
      "Epoch: 173||Train Loss: 0.974||Val Loss: 1.019||Val AUC: 0.906||Val AP: 0.899\n",
      "Epoch: 174||Train Loss: 0.973||Val Loss: 1.006||Val AUC: 0.906||Val AP: 0.900\n",
      "Epoch: 175||Train Loss: 0.972||Val Loss: 1.018||Val AUC: 0.906||Val AP: 0.899\n",
      "Epoch: 176||Train Loss: 0.969||Val Loss: 1.008||Val AUC: 0.906||Val AP: 0.900\n",
      "Epoch: 177||Train Loss: 0.965||Val Loss: 1.029||Val AUC: 0.905||Val AP: 0.900\n",
      "Epoch: 178||Train Loss: 0.964||Val Loss: 1.012||Val AUC: 0.907||Val AP: 0.901\n",
      "Epoch: 179||Train Loss: 0.961||Val Loss: 1.021||Val AUC: 0.907||Val AP: 0.902\n",
      "Epoch: 180||Train Loss: 0.958||Val Loss: 1.020||Val AUC: 0.907||Val AP: 0.901\n",
      "Epoch: 181||Train Loss: 0.954||Val Loss: 0.991||Val AUC: 0.908||Val AP: 0.902\n",
      "Epoch: 182||Train Loss: 0.954||Val Loss: 1.015||Val AUC: 0.908||Val AP: 0.902\n",
      "Epoch: 183||Train Loss: 0.953||Val Loss: 1.009||Val AUC: 0.907||Val AP: 0.902\n",
      "Epoch: 184||Train Loss: 0.943||Val Loss: 0.994||Val AUC: 0.908||Val AP: 0.902\n",
      "Epoch: 185||Train Loss: 0.948||Val Loss: 1.009||Val AUC: 0.907||Val AP: 0.901\n",
      "Epoch: 186||Train Loss: 0.942||Val Loss: 0.990||Val AUC: 0.910||Val AP: 0.904\n",
      "Epoch: 187||Train Loss: 0.939||Val Loss: 0.990||Val AUC: 0.911||Val AP: 0.905\n",
      "Epoch: 188||Train Loss: 0.934||Val Loss: 0.988||Val AUC: 0.912||Val AP: 0.906\n",
      "Epoch: 189||Train Loss: 0.931||Val Loss: 0.971||Val AUC: 0.912||Val AP: 0.906\n",
      "Epoch: 190||Train Loss: 0.931||Val Loss: 0.993||Val AUC: 0.911||Val AP: 0.905\n",
      "Epoch: 191||Train Loss: 0.928||Val Loss: 0.984||Val AUC: 0.912||Val AP: 0.906\n",
      "Epoch: 192||Train Loss: 0.924||Val Loss: 0.972||Val AUC: 0.913||Val AP: 0.907\n",
      "Epoch: 193||Train Loss: 0.924||Val Loss: 0.963||Val AUC: 0.914||Val AP: 0.909\n",
      "Epoch: 194||Train Loss: 0.921||Val Loss: 0.981||Val AUC: 0.912||Val AP: 0.907\n",
      "Epoch: 195||Train Loss: 0.919||Val Loss: 0.966||Val AUC: 0.913||Val AP: 0.908\n",
      "Epoch: 196||Train Loss: 0.914||Val Loss: 0.986||Val AUC: 0.912||Val AP: 0.906\n",
      "Epoch: 197||Train Loss: 0.913||Val Loss: 0.968||Val AUC: 0.914||Val AP: 0.910\n",
      "Epoch: 198||Train Loss: 0.912||Val Loss: 0.954||Val AUC: 0.916||Val AP: 0.910\n",
      "Epoch: 199||Train Loss: 0.909||Val Loss: 0.950||Val AUC: 0.917||Val AP: 0.912\n",
      "Epoch: 200||Train Loss: 0.907||Val Loss: 0.964||Val AUC: 0.917||Val AP: 0.912\n",
      "Epoch: 201||Train Loss: 0.902||Val Loss: 0.966||Val AUC: 0.916||Val AP: 0.911\n",
      "Epoch: 202||Train Loss: 0.900||Val Loss: 0.971||Val AUC: 0.916||Val AP: 0.910\n",
      "Epoch: 203||Train Loss: 0.897||Val Loss: 0.932||Val AUC: 0.919||Val AP: 0.914\n",
      "Epoch: 204||Train Loss: 0.896||Val Loss: 0.952||Val AUC: 0.917||Val AP: 0.912\n",
      "Epoch: 205||Train Loss: 0.894||Val Loss: 0.937||Val AUC: 0.920||Val AP: 0.915\n",
      "Epoch: 206||Train Loss: 0.889||Val Loss: 0.938||Val AUC: 0.919||Val AP: 0.914\n",
      "Epoch: 207||Train Loss: 0.886||Val Loss: 0.960||Val AUC: 0.918||Val AP: 0.913\n",
      "Epoch: 208||Train Loss: 0.884||Val Loss: 0.934||Val AUC: 0.919||Val AP: 0.915\n",
      "Epoch: 209||Train Loss: 0.881||Val Loss: 0.927||Val AUC: 0.920||Val AP: 0.915\n",
      "Epoch: 210||Train Loss: 0.880||Val Loss: 0.934||Val AUC: 0.921||Val AP: 0.917\n",
      "Epoch: 211||Train Loss: 0.877||Val Loss: 0.938||Val AUC: 0.920||Val AP: 0.916\n",
      "Epoch: 212||Train Loss: 0.879||Val Loss: 0.920||Val AUC: 0.922||Val AP: 0.917\n",
      "Epoch: 213||Train Loss: 0.873||Val Loss: 0.931||Val AUC: 0.921||Val AP: 0.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 214||Train Loss: 0.868||Val Loss: 0.918||Val AUC: 0.923||Val AP: 0.918\n",
      "Epoch: 215||Train Loss: 0.869||Val Loss: 0.920||Val AUC: 0.924||Val AP: 0.919\n",
      "Epoch: 216||Train Loss: 0.864||Val Loss: 0.921||Val AUC: 0.923||Val AP: 0.919\n",
      "Epoch: 217||Train Loss: 0.866||Val Loss: 0.945||Val AUC: 0.921||Val AP: 0.917\n",
      "Epoch: 218||Train Loss: 0.861||Val Loss: 0.907||Val AUC: 0.923||Val AP: 0.919\n",
      "Epoch: 219||Train Loss: 0.861||Val Loss: 0.909||Val AUC: 0.925||Val AP: 0.920\n",
      "Epoch: 220||Train Loss: 0.856||Val Loss: 0.901||Val AUC: 0.925||Val AP: 0.921\n",
      "Epoch: 221||Train Loss: 0.853||Val Loss: 0.911||Val AUC: 0.925||Val AP: 0.921\n",
      "Epoch: 222||Train Loss: 0.851||Val Loss: 0.909||Val AUC: 0.925||Val AP: 0.922\n",
      "Epoch: 223||Train Loss: 0.851||Val Loss: 0.897||Val AUC: 0.928||Val AP: 0.923\n",
      "Epoch: 224||Train Loss: 0.850||Val Loss: 0.911||Val AUC: 0.926||Val AP: 0.921\n",
      "Epoch: 225||Train Loss: 0.845||Val Loss: 0.901||Val AUC: 0.927||Val AP: 0.923\n",
      "Epoch: 226||Train Loss: 0.842||Val Loss: 0.895||Val AUC: 0.926||Val AP: 0.923\n",
      "Epoch: 227||Train Loss: 0.841||Val Loss: 0.913||Val AUC: 0.925||Val AP: 0.921\n",
      "Epoch: 228||Train Loss: 0.839||Val Loss: 0.884||Val AUC: 0.928||Val AP: 0.924\n",
      "Epoch: 229||Train Loss: 0.834||Val Loss: 0.881||Val AUC: 0.927||Val AP: 0.924\n",
      "Epoch: 230||Train Loss: 0.836||Val Loss: 0.882||Val AUC: 0.928||Val AP: 0.924\n",
      "Epoch: 231||Train Loss: 0.829||Val Loss: 0.872||Val AUC: 0.929||Val AP: 0.925\n",
      "Epoch: 232||Train Loss: 0.829||Val Loss: 0.886||Val AUC: 0.929||Val AP: 0.924\n",
      "Epoch: 233||Train Loss: 0.829||Val Loss: 0.871||Val AUC: 0.930||Val AP: 0.926\n",
      "Epoch: 234||Train Loss: 0.826||Val Loss: 0.891||Val AUC: 0.929||Val AP: 0.925\n",
      "Epoch: 235||Train Loss: 0.825||Val Loss: 0.870||Val AUC: 0.930||Val AP: 0.927\n",
      "Epoch: 236||Train Loss: 0.821||Val Loss: 0.871||Val AUC: 0.929||Val AP: 0.926\n",
      "Epoch: 237||Train Loss: 0.817||Val Loss: 0.867||Val AUC: 0.930||Val AP: 0.926\n",
      "Epoch: 238||Train Loss: 0.817||Val Loss: 0.861||Val AUC: 0.932||Val AP: 0.928\n",
      "Epoch: 239||Train Loss: 0.816||Val Loss: 0.859||Val AUC: 0.932||Val AP: 0.929\n",
      "Epoch: 240||Train Loss: 0.814||Val Loss: 0.865||Val AUC: 0.931||Val AP: 0.927\n",
      "Epoch: 241||Train Loss: 0.813||Val Loss: 0.858||Val AUC: 0.932||Val AP: 0.928\n",
      "Epoch: 242||Train Loss: 0.809||Val Loss: 0.864||Val AUC: 0.932||Val AP: 0.928\n",
      "Epoch: 243||Train Loss: 0.806||Val Loss: 0.873||Val AUC: 0.930||Val AP: 0.927\n",
      "Epoch: 244||Train Loss: 0.806||Val Loss: 0.872||Val AUC: 0.931||Val AP: 0.928\n",
      "Epoch: 245||Train Loss: 0.802||Val Loss: 0.859||Val AUC: 0.932||Val AP: 0.928\n",
      "Epoch: 246||Train Loss: 0.800||Val Loss: 0.856||Val AUC: 0.933||Val AP: 0.930\n",
      "Epoch: 247||Train Loss: 0.797||Val Loss: 0.841||Val AUC: 0.934||Val AP: 0.931\n",
      "Epoch: 248||Train Loss: 0.798||Val Loss: 0.859||Val AUC: 0.934||Val AP: 0.930\n",
      "Epoch: 249||Train Loss: 0.797||Val Loss: 0.862||Val AUC: 0.932||Val AP: 0.929\n",
      "Epoch: 250||Train Loss: 0.794||Val Loss: 0.851||Val AUC: 0.932||Val AP: 0.929\n",
      "Epoch: 251||Train Loss: 0.793||Val Loss: 0.851||Val AUC: 0.933||Val AP: 0.930\n",
      "Epoch: 252||Train Loss: 0.792||Val Loss: 0.840||Val AUC: 0.934||Val AP: 0.931\n",
      "Epoch: 253||Train Loss: 0.787||Val Loss: 0.830||Val AUC: 0.935||Val AP: 0.932\n",
      "Epoch: 254||Train Loss: 0.786||Val Loss: 0.821||Val AUC: 0.936||Val AP: 0.933\n",
      "Epoch: 255||Train Loss: 0.784||Val Loss: 0.838||Val AUC: 0.936||Val AP: 0.933\n",
      "Epoch: 256||Train Loss: 0.783||Val Loss: 0.833||Val AUC: 0.937||Val AP: 0.934\n",
      "Epoch: 257||Train Loss: 0.779||Val Loss: 0.828||Val AUC: 0.937||Val AP: 0.933\n",
      "Epoch: 258||Train Loss: 0.778||Val Loss: 0.834||Val AUC: 0.936||Val AP: 0.933\n",
      "Epoch: 259||Train Loss: 0.779||Val Loss: 0.832||Val AUC: 0.936||Val AP: 0.933\n",
      "Epoch: 260||Train Loss: 0.775||Val Loss: 0.828||Val AUC: 0.936||Val AP: 0.933\n",
      "Epoch: 261||Train Loss: 0.773||Val Loss: 0.822||Val AUC: 0.937||Val AP: 0.934\n",
      "Epoch: 262||Train Loss: 0.771||Val Loss: 0.806||Val AUC: 0.939||Val AP: 0.936\n",
      "Epoch: 263||Train Loss: 0.771||Val Loss: 0.826||Val AUC: 0.937||Val AP: 0.934\n",
      "Epoch: 264||Train Loss: 0.766||Val Loss: 0.820||Val AUC: 0.938||Val AP: 0.935\n",
      "Epoch: 265||Train Loss: 0.765||Val Loss: 0.830||Val AUC: 0.938||Val AP: 0.935\n",
      "Epoch: 266||Train Loss: 0.764||Val Loss: 0.813||Val AUC: 0.939||Val AP: 0.936\n",
      "Epoch: 267||Train Loss: 0.761||Val Loss: 0.823||Val AUC: 0.938||Val AP: 0.934\n",
      "Epoch: 268||Train Loss: 0.761||Val Loss: 0.817||Val AUC: 0.938||Val AP: 0.935\n",
      "Epoch: 269||Train Loss: 0.760||Val Loss: 0.817||Val AUC: 0.938||Val AP: 0.936\n",
      "Epoch: 270||Train Loss: 0.757||Val Loss: 0.815||Val AUC: 0.939||Val AP: 0.936\n",
      "Epoch: 271||Train Loss: 0.755||Val Loss: 0.816||Val AUC: 0.939||Val AP: 0.936\n",
      "Epoch: 272||Train Loss: 0.752||Val Loss: 0.791||Val AUC: 0.941||Val AP: 0.938\n",
      "Epoch: 273||Train Loss: 0.751||Val Loss: 0.783||Val AUC: 0.941||Val AP: 0.937\n",
      "Epoch: 274||Train Loss: 0.750||Val Loss: 0.795||Val AUC: 0.940||Val AP: 0.937\n",
      "Epoch: 275||Train Loss: 0.749||Val Loss: 0.804||Val AUC: 0.939||Val AP: 0.937\n",
      "Epoch: 276||Train Loss: 0.750||Val Loss: 0.808||Val AUC: 0.940||Val AP: 0.937\n",
      "Epoch: 277||Train Loss: 0.744||Val Loss: 0.799||Val AUC: 0.940||Val AP: 0.937\n",
      "Epoch: 278||Train Loss: 0.744||Val Loss: 0.800||Val AUC: 0.941||Val AP: 0.938\n",
      "Epoch: 279||Train Loss: 0.742||Val Loss: 0.789||Val AUC: 0.940||Val AP: 0.938\n",
      "Epoch: 280||Train Loss: 0.741||Val Loss: 0.810||Val AUC: 0.940||Val AP: 0.937\n",
      "Epoch: 281||Train Loss: 0.740||Val Loss: 0.788||Val AUC: 0.941||Val AP: 0.939\n",
      "Epoch: 282||Train Loss: 0.736||Val Loss: 0.797||Val AUC: 0.941||Val AP: 0.938\n",
      "Epoch: 283||Train Loss: 0.733||Val Loss: 0.778||Val AUC: 0.942||Val AP: 0.939\n",
      "Epoch: 284||Train Loss: 0.731||Val Loss: 0.795||Val AUC: 0.942||Val AP: 0.939\n",
      "Epoch: 285||Train Loss: 0.731||Val Loss: 0.780||Val AUC: 0.942||Val AP: 0.939\n",
      "Epoch: 286||Train Loss: 0.730||Val Loss: 0.788||Val AUC: 0.942||Val AP: 0.939\n",
      "Epoch: 287||Train Loss: 0.726||Val Loss: 0.772||Val AUC: 0.942||Val AP: 0.940\n",
      "Epoch: 288||Train Loss: 0.727||Val Loss: 0.779||Val AUC: 0.943||Val AP: 0.940\n",
      "Epoch: 289||Train Loss: 0.725||Val Loss: 0.776||Val AUC: 0.944||Val AP: 0.941\n",
      "Epoch: 290||Train Loss: 0.725||Val Loss: 0.764||Val AUC: 0.944||Val AP: 0.942\n",
      "Epoch: 291||Train Loss: 0.720||Val Loss: 0.780||Val AUC: 0.942||Val AP: 0.940\n",
      "Epoch: 292||Train Loss: 0.719||Val Loss: 0.771||Val AUC: 0.944||Val AP: 0.942\n",
      "Epoch: 293||Train Loss: 0.718||Val Loss: 0.782||Val AUC: 0.943||Val AP: 0.940\n",
      "Epoch: 294||Train Loss: 0.717||Val Loss: 0.773||Val AUC: 0.943||Val AP: 0.941\n",
      "Epoch: 295||Train Loss: 0.716||Val Loss: 0.765||Val AUC: 0.944||Val AP: 0.941\n",
      "Epoch: 296||Train Loss: 0.711||Val Loss: 0.759||Val AUC: 0.945||Val AP: 0.942\n",
      "Epoch: 297||Train Loss: 0.713||Val Loss: 0.769||Val AUC: 0.944||Val AP: 0.942\n",
      "Epoch: 298||Train Loss: 0.709||Val Loss: 0.754||Val AUC: 0.946||Val AP: 0.943\n",
      "Epoch: 299||Train Loss: 0.708||Val Loss: 0.769||Val AUC: 0.945||Val AP: 0.942\n",
      "Epoch: 300||Train Loss: 0.708||Val Loss: 0.755||Val AUC: 0.945||Val AP: 0.943\n",
      "Epoch: 301||Train Loss: 0.706||Val Loss: 0.764||Val AUC: 0.945||Val AP: 0.942\n",
      "Epoch: 302||Train Loss: 0.704||Val Loss: 0.743||Val AUC: 0.946||Val AP: 0.943\n",
      "Epoch: 303||Train Loss: 0.704||Val Loss: 0.751||Val AUC: 0.945||Val AP: 0.943\n",
      "Epoch: 304||Train Loss: 0.700||Val Loss: 0.747||Val AUC: 0.946||Val AP: 0.943\n",
      "Epoch: 305||Train Loss: 0.698||Val Loss: 0.739||Val AUC: 0.947||Val AP: 0.945\n",
      "Epoch: 306||Train Loss: 0.698||Val Loss: 0.740||Val AUC: 0.946||Val AP: 0.944\n",
      "Epoch: 307||Train Loss: 0.697||Val Loss: 0.738||Val AUC: 0.946||Val AP: 0.944\n",
      "Epoch: 308||Train Loss: 0.694||Val Loss: 0.746||Val AUC: 0.946||Val AP: 0.944\n",
      "Epoch: 309||Train Loss: 0.691||Val Loss: 0.732||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 310||Train Loss: 0.691||Val Loss: 0.734||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 311||Train Loss: 0.692||Val Loss: 0.764||Val AUC: 0.946||Val AP: 0.943\n",
      "Epoch: 312||Train Loss: 0.688||Val Loss: 0.745||Val AUC: 0.946||Val AP: 0.944\n",
      "Epoch: 313||Train Loss: 0.689||Val Loss: 0.744||Val AUC: 0.948||Val AP: 0.945\n",
      "Epoch: 314||Train Loss: 0.688||Val Loss: 0.736||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 315||Train Loss: 0.683||Val Loss: 0.733||Val AUC: 0.949||Val AP: 0.947\n",
      "Epoch: 316||Train Loss: 0.682||Val Loss: 0.728||Val AUC: 0.949||Val AP: 0.947\n",
      "Epoch: 317||Train Loss: 0.682||Val Loss: 0.714||Val AUC: 0.949||Val AP: 0.947\n",
      "Epoch: 318||Train Loss: 0.680||Val Loss: 0.732||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 319||Train Loss: 0.679||Val Loss: 0.730||Val AUC: 0.948||Val AP: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320||Train Loss: 0.681||Val Loss: 0.735||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 321||Train Loss: 0.675||Val Loss: 0.728||Val AUC: 0.948||Val AP: 0.946\n",
      "Epoch: 322||Train Loss: 0.676||Val Loss: 0.727||Val AUC: 0.949||Val AP: 0.947\n",
      "Epoch: 323||Train Loss: 0.671||Val Loss: 0.724||Val AUC: 0.950||Val AP: 0.947\n",
      "Epoch: 324||Train Loss: 0.670||Val Loss: 0.723||Val AUC: 0.950||Val AP: 0.948\n",
      "Epoch: 325||Train Loss: 0.667||Val Loss: 0.723||Val AUC: 0.951||Val AP: 0.949\n",
      "Epoch: 326||Train Loss: 0.670||Val Loss: 0.718||Val AUC: 0.950||Val AP: 0.948\n",
      "Epoch: 327||Train Loss: 0.668||Val Loss: 0.733||Val AUC: 0.949||Val AP: 0.948\n",
      "Epoch: 328||Train Loss: 0.665||Val Loss: 0.715||Val AUC: 0.950||Val AP: 0.949\n",
      "Epoch: 329||Train Loss: 0.664||Val Loss: 0.716||Val AUC: 0.952||Val AP: 0.950\n",
      "Epoch: 330||Train Loss: 0.661||Val Loss: 0.716||Val AUC: 0.951||Val AP: 0.949\n",
      "Epoch: 331||Train Loss: 0.660||Val Loss: 0.709||Val AUC: 0.951||Val AP: 0.949\n",
      "Epoch: 332||Train Loss: 0.660||Val Loss: 0.706||Val AUC: 0.951||Val AP: 0.949\n",
      "Epoch: 333||Train Loss: 0.658||Val Loss: 0.712||Val AUC: 0.950||Val AP: 0.948\n",
      "Epoch: 334||Train Loss: 0.656||Val Loss: 0.698||Val AUC: 0.952||Val AP: 0.950\n",
      "Epoch: 335||Train Loss: 0.655||Val Loss: 0.707||Val AUC: 0.952||Val AP: 0.950\n",
      "Epoch: 336||Train Loss: 0.654||Val Loss: 0.703||Val AUC: 0.952||Val AP: 0.949\n",
      "Epoch: 337||Train Loss: 0.653||Val Loss: 0.705||Val AUC: 0.952||Val AP: 0.950\n",
      "Epoch: 338||Train Loss: 0.651||Val Loss: 0.692||Val AUC: 0.953||Val AP: 0.951\n",
      "Epoch: 339||Train Loss: 0.650||Val Loss: 0.704||Val AUC: 0.951||Val AP: 0.950\n",
      "Epoch: 340||Train Loss: 0.647||Val Loss: 0.689||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 341||Train Loss: 0.646||Val Loss: 0.694||Val AUC: 0.953||Val AP: 0.951\n",
      "Epoch: 342||Train Loss: 0.645||Val Loss: 0.706||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 343||Train Loss: 0.648||Val Loss: 0.695||Val AUC: 0.954||Val AP: 0.953\n",
      "Epoch: 344||Train Loss: 0.646||Val Loss: 0.698||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 345||Train Loss: 0.642||Val Loss: 0.693||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 346||Train Loss: 0.641||Val Loss: 0.690||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 347||Train Loss: 0.638||Val Loss: 0.699||Val AUC: 0.953||Val AP: 0.951\n",
      "Epoch: 348||Train Loss: 0.637||Val Loss: 0.690||Val AUC: 0.954||Val AP: 0.953\n",
      "Epoch: 349||Train Loss: 0.634||Val Loss: 0.694||Val AUC: 0.954||Val AP: 0.953\n",
      "Epoch: 350||Train Loss: 0.636||Val Loss: 0.690||Val AUC: 0.955||Val AP: 0.953\n",
      "Epoch: 351||Train Loss: 0.632||Val Loss: 0.691||Val AUC: 0.955||Val AP: 0.953\n",
      "Epoch: 352||Train Loss: 0.631||Val Loss: 0.688||Val AUC: 0.954||Val AP: 0.952\n",
      "Epoch: 353||Train Loss: 0.632||Val Loss: 0.687||Val AUC: 0.954||Val AP: 0.953\n",
      "Epoch: 354||Train Loss: 0.630||Val Loss: 0.676||Val AUC: 0.956||Val AP: 0.954\n",
      "Epoch: 355||Train Loss: 0.629||Val Loss: 0.688||Val AUC: 0.955||Val AP: 0.954\n",
      "Epoch: 356||Train Loss: 0.629||Val Loss: 0.668||Val AUC: 0.955||Val AP: 0.954\n",
      "Epoch: 357||Train Loss: 0.628||Val Loss: 0.677||Val AUC: 0.955||Val AP: 0.954\n",
      "Epoch: 358||Train Loss: 0.625||Val Loss: 0.677||Val AUC: 0.955||Val AP: 0.954\n",
      "Epoch: 359||Train Loss: 0.624||Val Loss: 0.678||Val AUC: 0.955||Val AP: 0.953\n",
      "Epoch: 360||Train Loss: 0.622||Val Loss: 0.667||Val AUC: 0.957||Val AP: 0.955\n",
      "Epoch: 361||Train Loss: 0.621||Val Loss: 0.673||Val AUC: 0.955||Val AP: 0.954\n",
      "Epoch: 362||Train Loss: 0.622||Val Loss: 0.671||Val AUC: 0.956||Val AP: 0.954\n",
      "Epoch: 363||Train Loss: 0.619||Val Loss: 0.668||Val AUC: 0.956||Val AP: 0.955\n",
      "Epoch: 364||Train Loss: 0.616||Val Loss: 0.667||Val AUC: 0.957||Val AP: 0.956\n",
      "Epoch: 365||Train Loss: 0.618||Val Loss: 0.670||Val AUC: 0.957||Val AP: 0.956\n",
      "Epoch: 366||Train Loss: 0.614||Val Loss: 0.663||Val AUC: 0.957||Val AP: 0.955\n",
      "Epoch: 367||Train Loss: 0.612||Val Loss: 0.672||Val AUC: 0.957||Val AP: 0.955\n",
      "Epoch: 368||Train Loss: 0.613||Val Loss: 0.674||Val AUC: 0.957||Val AP: 0.955\n",
      "Epoch: 369||Train Loss: 0.612||Val Loss: 0.667||Val AUC: 0.957||Val AP: 0.956\n",
      "Epoch: 370||Train Loss: 0.611||Val Loss: 0.656||Val AUC: 0.958||Val AP: 0.956\n",
      "Epoch: 371||Train Loss: 0.612||Val Loss: 0.668||Val AUC: 0.957||Val AP: 0.955\n",
      "Epoch: 372||Train Loss: 0.608||Val Loss: 0.660||Val AUC: 0.956||Val AP: 0.955\n",
      "Epoch: 373||Train Loss: 0.607||Val Loss: 0.660||Val AUC: 0.958||Val AP: 0.957\n",
      "Epoch: 374||Train Loss: 0.604||Val Loss: 0.662||Val AUC: 0.958||Val AP: 0.956\n",
      "Epoch: 375||Train Loss: 0.603||Val Loss: 0.643||Val AUC: 0.959||Val AP: 0.957\n",
      "Epoch: 376||Train Loss: 0.605||Val Loss: 0.647||Val AUC: 0.959||Val AP: 0.957\n",
      "Epoch: 377||Train Loss: 0.602||Val Loss: 0.655||Val AUC: 0.958||Val AP: 0.957\n",
      "Epoch: 378||Train Loss: 0.599||Val Loss: 0.647||Val AUC: 0.959||Val AP: 0.958\n",
      "Epoch: 379||Train Loss: 0.599||Val Loss: 0.650||Val AUC: 0.959||Val AP: 0.958\n",
      "Epoch: 380||Train Loss: 0.598||Val Loss: 0.649||Val AUC: 0.959||Val AP: 0.957\n",
      "Epoch: 381||Train Loss: 0.595||Val Loss: 0.656||Val AUC: 0.958||Val AP: 0.956\n",
      "Epoch: 382||Train Loss: 0.594||Val Loss: 0.649||Val AUC: 0.959||Val AP: 0.957\n",
      "Epoch: 383||Train Loss: 0.593||Val Loss: 0.641||Val AUC: 0.960||Val AP: 0.958\n",
      "Epoch: 384||Train Loss: 0.593||Val Loss: 0.638||Val AUC: 0.961||Val AP: 0.959\n",
      "Epoch: 385||Train Loss: 0.591||Val Loss: 0.651||Val AUC: 0.960||Val AP: 0.958\n",
      "Epoch: 386||Train Loss: 0.591||Val Loss: 0.646||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 387||Train Loss: 0.588||Val Loss: 0.642||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 388||Train Loss: 0.586||Val Loss: 0.650||Val AUC: 0.959||Val AP: 0.958\n",
      "Epoch: 389||Train Loss: 0.588||Val Loss: 0.646||Val AUC: 0.960||Val AP: 0.958\n",
      "Epoch: 390||Train Loss: 0.585||Val Loss: 0.644||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 391||Train Loss: 0.584||Val Loss: 0.634||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 392||Train Loss: 0.582||Val Loss: 0.642||Val AUC: 0.960||Val AP: 0.958\n",
      "Epoch: 393||Train Loss: 0.584||Val Loss: 0.634||Val AUC: 0.961||Val AP: 0.959\n",
      "Epoch: 394||Train Loss: 0.580||Val Loss: 0.635||Val AUC: 0.961||Val AP: 0.959\n",
      "Epoch: 395||Train Loss: 0.580||Val Loss: 0.644||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 396||Train Loss: 0.579||Val Loss: 0.634||Val AUC: 0.961||Val AP: 0.959\n",
      "Epoch: 397||Train Loss: 0.580||Val Loss: 0.632||Val AUC: 0.960||Val AP: 0.959\n",
      "Epoch: 398||Train Loss: 0.575||Val Loss: 0.625||Val AUC: 0.962||Val AP: 0.960\n",
      "Epoch: 399||Train Loss: 0.575||Val Loss: 0.624||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 400||Train Loss: 0.574||Val Loss: 0.611||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 401||Train Loss: 0.574||Val Loss: 0.625||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 402||Train Loss: 0.572||Val Loss: 0.620||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 403||Train Loss: 0.572||Val Loss: 0.631||Val AUC: 0.961||Val AP: 0.960\n",
      "Epoch: 404||Train Loss: 0.569||Val Loss: 0.618||Val AUC: 0.963||Val AP: 0.961\n",
      "Epoch: 405||Train Loss: 0.570||Val Loss: 0.604||Val AUC: 0.964||Val AP: 0.963\n",
      "Epoch: 406||Train Loss: 0.567||Val Loss: 0.616||Val AUC: 0.963||Val AP: 0.962\n",
      "Epoch: 407||Train Loss: 0.565||Val Loss: 0.617||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 408||Train Loss: 0.564||Val Loss: 0.612||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 409||Train Loss: 0.566||Val Loss: 0.608||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 410||Train Loss: 0.563||Val Loss: 0.604||Val AUC: 0.963||Val AP: 0.961\n",
      "Epoch: 411||Train Loss: 0.560||Val Loss: 0.618||Val AUC: 0.962||Val AP: 0.961\n",
      "Epoch: 412||Train Loss: 0.562||Val Loss: 0.611||Val AUC: 0.963||Val AP: 0.961\n",
      "Epoch: 413||Train Loss: 0.560||Val Loss: 0.637||Val AUC: 0.962||Val AP: 0.960\n",
      "Epoch: 414||Train Loss: 0.560||Val Loss: 0.609||Val AUC: 0.963||Val AP: 0.961\n",
      "Epoch: 415||Train Loss: 0.559||Val Loss: 0.605||Val AUC: 0.964||Val AP: 0.963\n",
      "Epoch: 416||Train Loss: 0.557||Val Loss: 0.608||Val AUC: 0.963||Val AP: 0.962\n",
      "Epoch: 417||Train Loss: 0.556||Val Loss: 0.605||Val AUC: 0.964||Val AP: 0.963\n",
      "Epoch: 418||Train Loss: 0.555||Val Loss: 0.614||Val AUC: 0.963||Val AP: 0.962\n",
      "Epoch: 419||Train Loss: 0.553||Val Loss: 0.603||Val AUC: 0.964||Val AP: 0.962\n",
      "Epoch: 420||Train Loss: 0.552||Val Loss: 0.603||Val AUC: 0.965||Val AP: 0.963\n",
      "Epoch: 421||Train Loss: 0.550||Val Loss: 0.600||Val AUC: 0.965||Val AP: 0.963\n",
      "Epoch: 422||Train Loss: 0.551||Val Loss: 0.592||Val AUC: 0.965||Val AP: 0.964\n",
      "Epoch: 423||Train Loss: 0.548||Val Loss: 0.608||Val AUC: 0.964||Val AP: 0.962\n",
      "Epoch: 424||Train Loss: 0.548||Val Loss: 0.593||Val AUC: 0.965||Val AP: 0.964\n",
      "Epoch: 425||Train Loss: 0.546||Val Loss: 0.597||Val AUC: 0.965||Val AP: 0.964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 426||Train Loss: 0.546||Val Loss: 0.591||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 427||Train Loss: 0.545||Val Loss: 0.602||Val AUC: 0.964||Val AP: 0.963\n",
      "Epoch: 428||Train Loss: 0.543||Val Loss: 0.584||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 429||Train Loss: 0.544||Val Loss: 0.592||Val AUC: 0.966||Val AP: 0.964\n",
      "Epoch: 430||Train Loss: 0.542||Val Loss: 0.588||Val AUC: 0.965||Val AP: 0.964\n",
      "Epoch: 431||Train Loss: 0.540||Val Loss: 0.588||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 432||Train Loss: 0.540||Val Loss: 0.589||Val AUC: 0.965||Val AP: 0.964\n",
      "Epoch: 433||Train Loss: 0.538||Val Loss: 0.592||Val AUC: 0.964||Val AP: 0.963\n",
      "Epoch: 434||Train Loss: 0.536||Val Loss: 0.583||Val AUC: 0.965||Val AP: 0.964\n",
      "Epoch: 435||Train Loss: 0.538||Val Loss: 0.579||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 436||Train Loss: 0.535||Val Loss: 0.584||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 437||Train Loss: 0.533||Val Loss: 0.587||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 438||Train Loss: 0.532||Val Loss: 0.577||Val AUC: 0.967||Val AP: 0.965\n",
      "Epoch: 439||Train Loss: 0.533||Val Loss: 0.587||Val AUC: 0.966||Val AP: 0.965\n",
      "Epoch: 440||Train Loss: 0.532||Val Loss: 0.569||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 441||Train Loss: 0.532||Val Loss: 0.577||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 442||Train Loss: 0.528||Val Loss: 0.587||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 443||Train Loss: 0.528||Val Loss: 0.575||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 444||Train Loss: 0.528||Val Loss: 0.574||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 445||Train Loss: 0.527||Val Loss: 0.572||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 446||Train Loss: 0.525||Val Loss: 0.559||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 447||Train Loss: 0.525||Val Loss: 0.562||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 448||Train Loss: 0.522||Val Loss: 0.574||Val AUC: 0.967||Val AP: 0.966\n",
      "Epoch: 449||Train Loss: 0.520||Val Loss: 0.570||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 450||Train Loss: 0.522||Val Loss: 0.571||Val AUC: 0.968||Val AP: 0.966\n",
      "Epoch: 451||Train Loss: 0.521||Val Loss: 0.573||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 452||Train Loss: 0.520||Val Loss: 0.572||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 453||Train Loss: 0.518||Val Loss: 0.562||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 454||Train Loss: 0.518||Val Loss: 0.562||Val AUC: 0.968||Val AP: 0.968\n",
      "Epoch: 455||Train Loss: 0.515||Val Loss: 0.569||Val AUC: 0.968||Val AP: 0.966\n",
      "Epoch: 456||Train Loss: 0.516||Val Loss: 0.566||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 457||Train Loss: 0.514||Val Loss: 0.556||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 458||Train Loss: 0.515||Val Loss: 0.568||Val AUC: 0.969||Val AP: 0.967\n",
      "Epoch: 459||Train Loss: 0.515||Val Loss: 0.569||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 460||Train Loss: 0.513||Val Loss: 0.568||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 461||Train Loss: 0.513||Val Loss: 0.564||Val AUC: 0.968||Val AP: 0.967\n",
      "Epoch: 462||Train Loss: 0.508||Val Loss: 0.555||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 463||Train Loss: 0.507||Val Loss: 0.557||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 464||Train Loss: 0.506||Val Loss: 0.544||Val AUC: 0.970||Val AP: 0.969\n",
      "Epoch: 465||Train Loss: 0.507||Val Loss: 0.558||Val AUC: 0.969||Val AP: 0.969\n",
      "Epoch: 466||Train Loss: 0.508||Val Loss: 0.550||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 467||Train Loss: 0.509||Val Loss: 0.550||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 468||Train Loss: 0.505||Val Loss: 0.551||Val AUC: 0.970||Val AP: 0.969\n",
      "Epoch: 469||Train Loss: 0.503||Val Loss: 0.544||Val AUC: 0.969||Val AP: 0.969\n",
      "Epoch: 470||Train Loss: 0.503||Val Loss: 0.545||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 471||Train Loss: 0.500||Val Loss: 0.549||Val AUC: 0.970||Val AP: 0.969\n",
      "Epoch: 472||Train Loss: 0.502||Val Loss: 0.566||Val AUC: 0.969||Val AP: 0.968\n",
      "Epoch: 473||Train Loss: 0.499||Val Loss: 0.557||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 474||Train Loss: 0.498||Val Loss: 0.553||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 475||Train Loss: 0.497||Val Loss: 0.557||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 476||Train Loss: 0.497||Val Loss: 0.549||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 477||Train Loss: 0.494||Val Loss: 0.547||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 478||Train Loss: 0.495||Val Loss: 0.541||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 479||Train Loss: 0.494||Val Loss: 0.547||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 480||Train Loss: 0.495||Val Loss: 0.537||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 481||Train Loss: 0.491||Val Loss: 0.539||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 482||Train Loss: 0.489||Val Loss: 0.545||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 483||Train Loss: 0.489||Val Loss: 0.539||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 484||Train Loss: 0.490||Val Loss: 0.531||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 485||Train Loss: 0.488||Val Loss: 0.534||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 486||Train Loss: 0.488||Val Loss: 0.536||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 487||Train Loss: 0.487||Val Loss: 0.535||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 488||Train Loss: 0.489||Val Loss: 0.533||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 489||Train Loss: 0.486||Val Loss: 0.525||Val AUC: 0.972||Val AP: 0.972\n",
      "Epoch: 490||Train Loss: 0.482||Val Loss: 0.538||Val AUC: 0.971||Val AP: 0.970\n",
      "Epoch: 491||Train Loss: 0.485||Val Loss: 0.539||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 492||Train Loss: 0.481||Val Loss: 0.522||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 493||Train Loss: 0.481||Val Loss: 0.532||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 494||Train Loss: 0.481||Val Loss: 0.525||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 495||Train Loss: 0.478||Val Loss: 0.535||Val AUC: 0.972||Val AP: 0.970\n",
      "Epoch: 496||Train Loss: 0.477||Val Loss: 0.515||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 497||Train Loss: 0.478||Val Loss: 0.522||Val AUC: 0.972||Val AP: 0.971\n",
      "Epoch: 498||Train Loss: 0.477||Val Loss: 0.525||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 499||Train Loss: 0.474||Val Loss: 0.526||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 500||Train Loss: 0.474||Val Loss: 0.526||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 501||Train Loss: 0.473||Val Loss: 0.533||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 502||Train Loss: 0.474||Val Loss: 0.519||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 503||Train Loss: 0.472||Val Loss: 0.517||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 504||Train Loss: 0.470||Val Loss: 0.515||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 505||Train Loss: 0.471||Val Loss: 0.513||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 506||Train Loss: 0.470||Val Loss: 0.509||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 507||Train Loss: 0.469||Val Loss: 0.508||Val AUC: 0.973||Val AP: 0.973\n",
      "Epoch: 508||Train Loss: 0.466||Val Loss: 0.506||Val AUC: 0.973||Val AP: 0.972\n",
      "Epoch: 509||Train Loss: 0.465||Val Loss: 0.503||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 510||Train Loss: 0.467||Val Loss: 0.518||Val AUC: 0.973||Val AP: 0.973\n",
      "Epoch: 511||Train Loss: 0.468||Val Loss: 0.517||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 512||Train Loss: 0.465||Val Loss: 0.516||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 513||Train Loss: 0.464||Val Loss: 0.500||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 514||Train Loss: 0.465||Val Loss: 0.506||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 515||Train Loss: 0.464||Val Loss: 0.508||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 516||Train Loss: 0.463||Val Loss: 0.513||Val AUC: 0.974||Val AP: 0.974\n",
      "Epoch: 517||Train Loss: 0.462||Val Loss: 0.511||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 518||Train Loss: 0.460||Val Loss: 0.509||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 519||Train Loss: 0.459||Val Loss: 0.507||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 520||Train Loss: 0.459||Val Loss: 0.497||Val AUC: 0.974||Val AP: 0.974\n",
      "Epoch: 521||Train Loss: 0.459||Val Loss: 0.497||Val AUC: 0.974||Val AP: 0.974\n",
      "Epoch: 522||Train Loss: 0.457||Val Loss: 0.499||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 523||Train Loss: 0.454||Val Loss: 0.498||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 524||Train Loss: 0.452||Val Loss: 0.503||Val AUC: 0.974||Val AP: 0.974\n",
      "Epoch: 525||Train Loss: 0.453||Val Loss: 0.507||Val AUC: 0.974||Val AP: 0.974\n",
      "Epoch: 526||Train Loss: 0.451||Val Loss: 0.495||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 527||Train Loss: 0.451||Val Loss: 0.502||Val AUC: 0.974||Val AP: 0.973\n",
      "Epoch: 528||Train Loss: 0.453||Val Loss: 0.490||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 529||Train Loss: 0.451||Val Loss: 0.496||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 530||Train Loss: 0.450||Val Loss: 0.487||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 531||Train Loss: 0.449||Val Loss: 0.493||Val AUC: 0.976||Val AP: 0.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 532||Train Loss: 0.450||Val Loss: 0.494||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 533||Train Loss: 0.448||Val Loss: 0.495||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 534||Train Loss: 0.448||Val Loss: 0.493||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 535||Train Loss: 0.447||Val Loss: 0.486||Val AUC: 0.975||Val AP: 0.974\n",
      "Epoch: 536||Train Loss: 0.446||Val Loss: 0.487||Val AUC: 0.975||Val AP: 0.975\n",
      "Epoch: 537||Train Loss: 0.446||Val Loss: 0.494||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 538||Train Loss: 0.444||Val Loss: 0.491||Val AUC: 0.976||Val AP: 0.974\n",
      "Epoch: 539||Train Loss: 0.442||Val Loss: 0.491||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 540||Train Loss: 0.443||Val Loss: 0.493||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 541||Train Loss: 0.442||Val Loss: 0.488||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 542||Train Loss: 0.440||Val Loss: 0.490||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 543||Train Loss: 0.440||Val Loss: 0.483||Val AUC: 0.976||Val AP: 0.976\n",
      "Epoch: 544||Train Loss: 0.439||Val Loss: 0.478||Val AUC: 0.976||Val AP: 0.976\n",
      "Epoch: 545||Train Loss: 0.438||Val Loss: 0.478||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 546||Train Loss: 0.438||Val Loss: 0.475||Val AUC: 0.976||Val AP: 0.976\n",
      "Epoch: 547||Train Loss: 0.438||Val Loss: 0.486||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 548||Train Loss: 0.438||Val Loss: 0.476||Val AUC: 0.976||Val AP: 0.976\n",
      "Epoch: 549||Train Loss: 0.438||Val Loss: 0.478||Val AUC: 0.976||Val AP: 0.976\n",
      "Epoch: 550||Train Loss: 0.436||Val Loss: 0.476||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 551||Train Loss: 0.434||Val Loss: 0.472||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 552||Train Loss: 0.435||Val Loss: 0.476||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 553||Train Loss: 0.433||Val Loss: 0.469||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 554||Train Loss: 0.432||Val Loss: 0.483||Val AUC: 0.976||Val AP: 0.975\n",
      "Epoch: 555||Train Loss: 0.431||Val Loss: 0.474||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 556||Train Loss: 0.431||Val Loss: 0.468||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 557||Train Loss: 0.430||Val Loss: 0.484||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 558||Train Loss: 0.430||Val Loss: 0.478||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 559||Train Loss: 0.428||Val Loss: 0.471||Val AUC: 0.977||Val AP: 0.976\n",
      "Epoch: 560||Train Loss: 0.430||Val Loss: 0.467||Val AUC: 0.977||Val AP: 0.977\n",
      "Epoch: 561||Train Loss: 0.428||Val Loss: 0.474||Val AUC: 0.977||Val AP: 0.977\n",
      "Epoch: 562||Train Loss: 0.427||Val Loss: 0.471||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 563||Train Loss: 0.428||Val Loss: 0.476||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 564||Train Loss: 0.423||Val Loss: 0.475||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 565||Train Loss: 0.424||Val Loss: 0.471||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 566||Train Loss: 0.425||Val Loss: 0.462||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 567||Train Loss: 0.424||Val Loss: 0.470||Val AUC: 0.977||Val AP: 0.977\n",
      "Epoch: 568||Train Loss: 0.421||Val Loss: 0.466||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 569||Train Loss: 0.422||Val Loss: 0.476||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 570||Train Loss: 0.421||Val Loss: 0.461||Val AUC: 0.978||Val AP: 0.978\n",
      "Epoch: 571||Train Loss: 0.420||Val Loss: 0.468||Val AUC: 0.977||Val AP: 0.977\n",
      "Epoch: 572||Train Loss: 0.420||Val Loss: 0.468||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 573||Train Loss: 0.417||Val Loss: 0.462||Val AUC: 0.978||Val AP: 0.978\n",
      "Epoch: 574||Train Loss: 0.418||Val Loss: 0.459||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 575||Train Loss: 0.417||Val Loss: 0.457||Val AUC: 0.978||Val AP: 0.978\n",
      "Epoch: 576||Train Loss: 0.417||Val Loss: 0.464||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 577||Train Loss: 0.418||Val Loss: 0.467||Val AUC: 0.978||Val AP: 0.977\n",
      "Epoch: 578||Train Loss: 0.417||Val Loss: 0.456||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 579||Train Loss: 0.415||Val Loss: 0.455||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 580||Train Loss: 0.416||Val Loss: 0.461||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 581||Train Loss: 0.414||Val Loss: 0.466||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 582||Train Loss: 0.412||Val Loss: 0.451||Val AUC: 0.979||Val AP: 0.979\n",
      "Epoch: 583||Train Loss: 0.413||Val Loss: 0.458||Val AUC: 0.978||Val AP: 0.978\n",
      "Epoch: 584||Train Loss: 0.413||Val Loss: 0.454||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 585||Train Loss: 0.409||Val Loss: 0.454||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 586||Train Loss: 0.408||Val Loss: 0.459||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 587||Train Loss: 0.410||Val Loss: 0.458||Val AUC: 0.979||Val AP: 0.979\n",
      "Epoch: 588||Train Loss: 0.410||Val Loss: 0.449||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 589||Train Loss: 0.409||Val Loss: 0.460||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 590||Train Loss: 0.406||Val Loss: 0.450||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 591||Train Loss: 0.408||Val Loss: 0.447||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 592||Train Loss: 0.408||Val Loss: 0.442||Val AUC: 0.979||Val AP: 0.979\n",
      "Epoch: 593||Train Loss: 0.408||Val Loss: 0.448||Val AUC: 0.979||Val AP: 0.978\n",
      "Epoch: 594||Train Loss: 0.405||Val Loss: 0.442||Val AUC: 0.979||Val AP: 0.979\n",
      "Epoch: 595||Train Loss: 0.406||Val Loss: 0.437||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 596||Train Loss: 0.402||Val Loss: 0.440||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 597||Train Loss: 0.404||Val Loss: 0.443||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 598||Train Loss: 0.403||Val Loss: 0.445||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 599||Train Loss: 0.403||Val Loss: 0.446||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 600||Train Loss: 0.403||Val Loss: 0.453||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 601||Train Loss: 0.402||Val Loss: 0.442||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 602||Train Loss: 0.401||Val Loss: 0.436||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 603||Train Loss: 0.398||Val Loss: 0.440||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 604||Train Loss: 0.397||Val Loss: 0.439||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 605||Train Loss: 0.397||Val Loss: 0.432||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 606||Train Loss: 0.399||Val Loss: 0.438||Val AUC: 0.980||Val AP: 0.979\n",
      "Epoch: 607||Train Loss: 0.399||Val Loss: 0.437||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 608||Train Loss: 0.394||Val Loss: 0.446||Val AUC: 0.979||Val AP: 0.979\n",
      "Epoch: 609||Train Loss: 0.397||Val Loss: 0.435||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 610||Train Loss: 0.395||Val Loss: 0.426||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 611||Train Loss: 0.394||Val Loss: 0.435||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 612||Train Loss: 0.394||Val Loss: 0.434||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 613||Train Loss: 0.392||Val Loss: 0.435||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 614||Train Loss: 0.392||Val Loss: 0.442||Val AUC: 0.980||Val AP: 0.980\n",
      "Epoch: 615||Train Loss: 0.392||Val Loss: 0.434||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 616||Train Loss: 0.391||Val Loss: 0.430||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 617||Train Loss: 0.392||Val Loss: 0.429||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 618||Train Loss: 0.392||Val Loss: 0.431||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 619||Train Loss: 0.388||Val Loss: 0.429||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 620||Train Loss: 0.389||Val Loss: 0.431||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 621||Train Loss: 0.389||Val Loss: 0.435||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 622||Train Loss: 0.388||Val Loss: 0.433||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 623||Train Loss: 0.387||Val Loss: 0.433||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 624||Train Loss: 0.386||Val Loss: 0.438||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 625||Train Loss: 0.386||Val Loss: 0.428||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 626||Train Loss: 0.385||Val Loss: 0.433||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 627||Train Loss: 0.386||Val Loss: 0.425||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 628||Train Loss: 0.383||Val Loss: 0.422||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 629||Train Loss: 0.383||Val Loss: 0.417||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 630||Train Loss: 0.382||Val Loss: 0.423||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 631||Train Loss: 0.382||Val Loss: 0.424||Val AUC: 0.981||Val AP: 0.980\n",
      "Epoch: 632||Train Loss: 0.383||Val Loss: 0.420||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 633||Train Loss: 0.380||Val Loss: 0.421||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 634||Train Loss: 0.379||Val Loss: 0.422||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 635||Train Loss: 0.380||Val Loss: 0.424||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 636||Train Loss: 0.380||Val Loss: 0.416||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 637||Train Loss: 0.379||Val Loss: 0.425||Val AUC: 0.981||Val AP: 0.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 638||Train Loss: 0.380||Val Loss: 0.423||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 639||Train Loss: 0.380||Val Loss: 0.421||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 640||Train Loss: 0.378||Val Loss: 0.426||Val AUC: 0.981||Val AP: 0.981\n",
      "Epoch: 641||Train Loss: 0.377||Val Loss: 0.423||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 642||Train Loss: 0.376||Val Loss: 0.415||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 643||Train Loss: 0.373||Val Loss: 0.420||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 644||Train Loss: 0.376||Val Loss: 0.411||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 645||Train Loss: 0.375||Val Loss: 0.414||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 646||Train Loss: 0.376||Val Loss: 0.411||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 647||Train Loss: 0.372||Val Loss: 0.410||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 648||Train Loss: 0.372||Val Loss: 0.419||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 649||Train Loss: 0.373||Val Loss: 0.415||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 650||Train Loss: 0.373||Val Loss: 0.414||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 651||Train Loss: 0.371||Val Loss: 0.422||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 652||Train Loss: 0.370||Val Loss: 0.408||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 653||Train Loss: 0.371||Val Loss: 0.407||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 654||Train Loss: 0.370||Val Loss: 0.402||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 655||Train Loss: 0.370||Val Loss: 0.409||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 656||Train Loss: 0.369||Val Loss: 0.409||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 657||Train Loss: 0.367||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 658||Train Loss: 0.369||Val Loss: 0.404||Val AUC: 0.982||Val AP: 0.982\n",
      "Epoch: 659||Train Loss: 0.369||Val Loss: 0.406||Val AUC: 0.982||Val AP: 0.981\n",
      "Epoch: 660||Train Loss: 0.366||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 661||Train Loss: 0.366||Val Loss: 0.397||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 662||Train Loss: 0.366||Val Loss: 0.397||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 663||Train Loss: 0.365||Val Loss: 0.404||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 664||Train Loss: 0.363||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 665||Train Loss: 0.363||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 666||Train Loss: 0.361||Val Loss: 0.406||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 667||Train Loss: 0.362||Val Loss: 0.406||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 668||Train Loss: 0.360||Val Loss: 0.405||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 669||Train Loss: 0.363||Val Loss: 0.401||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 670||Train Loss: 0.361||Val Loss: 0.405||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 671||Train Loss: 0.360||Val Loss: 0.397||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 672||Train Loss: 0.359||Val Loss: 0.398||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 673||Train Loss: 0.361||Val Loss: 0.400||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 674||Train Loss: 0.358||Val Loss: 0.397||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 675||Train Loss: 0.358||Val Loss: 0.393||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 676||Train Loss: 0.358||Val Loss: 0.408||Val AUC: 0.983||Val AP: 0.982\n",
      "Epoch: 677||Train Loss: 0.359||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 678||Train Loss: 0.357||Val Loss: 0.402||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 679||Train Loss: 0.355||Val Loss: 0.394||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 680||Train Loss: 0.355||Val Loss: 0.400||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 681||Train Loss: 0.355||Val Loss: 0.394||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 682||Train Loss: 0.354||Val Loss: 0.391||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 683||Train Loss: 0.354||Val Loss: 0.396||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 684||Train Loss: 0.353||Val Loss: 0.398||Val AUC: 0.983||Val AP: 0.983\n",
      "Epoch: 685||Train Loss: 0.353||Val Loss: 0.391||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 686||Train Loss: 0.353||Val Loss: 0.391||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 687||Train Loss: 0.350||Val Loss: 0.391||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 688||Train Loss: 0.352||Val Loss: 0.391||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 689||Train Loss: 0.352||Val Loss: 0.389||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 690||Train Loss: 0.350||Val Loss: 0.393||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 691||Train Loss: 0.351||Val Loss: 0.387||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 692||Train Loss: 0.351||Val Loss: 0.386||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 693||Train Loss: 0.347||Val Loss: 0.390||Val AUC: 0.984||Val AP: 0.983\n",
      "Epoch: 694||Train Loss: 0.349||Val Loss: 0.386||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 695||Train Loss: 0.349||Val Loss: 0.386||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 696||Train Loss: 0.347||Val Loss: 0.379||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 697||Train Loss: 0.349||Val Loss: 0.376||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 698||Train Loss: 0.347||Val Loss: 0.381||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 699||Train Loss: 0.347||Val Loss: 0.381||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 700||Train Loss: 0.344||Val Loss: 0.380||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 701||Train Loss: 0.348||Val Loss: 0.383||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 702||Train Loss: 0.346||Val Loss: 0.386||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 703||Train Loss: 0.345||Val Loss: 0.378||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 704||Train Loss: 0.341||Val Loss: 0.381||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 705||Train Loss: 0.345||Val Loss: 0.385||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 706||Train Loss: 0.343||Val Loss: 0.383||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 707||Train Loss: 0.341||Val Loss: 0.387||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 708||Train Loss: 0.342||Val Loss: 0.377||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 709||Train Loss: 0.341||Val Loss: 0.377||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 710||Train Loss: 0.340||Val Loss: 0.380||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 711||Train Loss: 0.339||Val Loss: 0.384||Val AUC: 0.984||Val AP: 0.984\n",
      "Epoch: 712||Train Loss: 0.341||Val Loss: 0.378||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 713||Train Loss: 0.340||Val Loss: 0.373||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 714||Train Loss: 0.340||Val Loss: 0.374||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 715||Train Loss: 0.339||Val Loss: 0.369||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 716||Train Loss: 0.340||Val Loss: 0.378||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 717||Train Loss: 0.338||Val Loss: 0.381||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 718||Train Loss: 0.338||Val Loss: 0.386||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 719||Train Loss: 0.335||Val Loss: 0.377||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 720||Train Loss: 0.338||Val Loss: 0.384||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 721||Train Loss: 0.335||Val Loss: 0.376||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 722||Train Loss: 0.335||Val Loss: 0.368||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 723||Train Loss: 0.335||Val Loss: 0.372||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 724||Train Loss: 0.333||Val Loss: 0.366||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 725||Train Loss: 0.333||Val Loss: 0.365||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 726||Train Loss: 0.332||Val Loss: 0.369||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 727||Train Loss: 0.334||Val Loss: 0.373||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 728||Train Loss: 0.332||Val Loss: 0.371||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 729||Train Loss: 0.332||Val Loss: 0.375||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 730||Train Loss: 0.332||Val Loss: 0.377||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 731||Train Loss: 0.331||Val Loss: 0.367||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 732||Train Loss: 0.329||Val Loss: 0.375||Val AUC: 0.985||Val AP: 0.984\n",
      "Epoch: 733||Train Loss: 0.332||Val Loss: 0.369||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 734||Train Loss: 0.332||Val Loss: 0.373||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 735||Train Loss: 0.330||Val Loss: 0.364||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 736||Train Loss: 0.328||Val Loss: 0.371||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 737||Train Loss: 0.329||Val Loss: 0.365||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 738||Train Loss: 0.327||Val Loss: 0.361||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 739||Train Loss: 0.328||Val Loss: 0.366||Val AUC: 0.985||Val AP: 0.985\n",
      "Epoch: 740||Train Loss: 0.326||Val Loss: 0.368||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 741||Train Loss: 0.327||Val Loss: 0.365||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 742||Train Loss: 0.328||Val Loss: 0.356||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 743||Train Loss: 0.327||Val Loss: 0.362||Val AUC: 0.986||Val AP: 0.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 744||Train Loss: 0.324||Val Loss: 0.363||Val AUC: 0.986||Val AP: 0.985\n",
      "Epoch: 745||Train Loss: 0.326||Val Loss: 0.364||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 746||Train Loss: 0.323||Val Loss: 0.358||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 747||Train Loss: 0.324||Val Loss: 0.360||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 748||Train Loss: 0.324||Val Loss: 0.350||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 749||Train Loss: 0.322||Val Loss: 0.353||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 750||Train Loss: 0.323||Val Loss: 0.361||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 751||Train Loss: 0.322||Val Loss: 0.359||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 752||Train Loss: 0.323||Val Loss: 0.364||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 753||Train Loss: 0.321||Val Loss: 0.354||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 754||Train Loss: 0.321||Val Loss: 0.354||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 755||Train Loss: 0.324||Val Loss: 0.354||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 756||Train Loss: 0.321||Val Loss: 0.356||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 757||Train Loss: 0.319||Val Loss: 0.357||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 758||Train Loss: 0.320||Val Loss: 0.349||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 759||Train Loss: 0.319||Val Loss: 0.353||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 760||Train Loss: 0.319||Val Loss: 0.355||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 761||Train Loss: 0.319||Val Loss: 0.357||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 762||Train Loss: 0.319||Val Loss: 0.357||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 763||Train Loss: 0.317||Val Loss: 0.354||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 764||Train Loss: 0.316||Val Loss: 0.346||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 765||Train Loss: 0.317||Val Loss: 0.354||Val AUC: 0.986||Val AP: 0.986\n",
      "Epoch: 766||Train Loss: 0.316||Val Loss: 0.357||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 767||Train Loss: 0.316||Val Loss: 0.351||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 768||Train Loss: 0.316||Val Loss: 0.352||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 769||Train Loss: 0.316||Val Loss: 0.350||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 770||Train Loss: 0.316||Val Loss: 0.350||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 771||Train Loss: 0.314||Val Loss: 0.353||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 772||Train Loss: 0.312||Val Loss: 0.351||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 773||Train Loss: 0.313||Val Loss: 0.354||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 774||Train Loss: 0.312||Val Loss: 0.355||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 775||Train Loss: 0.311||Val Loss: 0.349||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 776||Train Loss: 0.312||Val Loss: 0.338||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 777||Train Loss: 0.312||Val Loss: 0.349||Val AUC: 0.987||Val AP: 0.986\n",
      "Epoch: 778||Train Loss: 0.311||Val Loss: 0.358||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 779||Train Loss: 0.311||Val Loss: 0.341||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 780||Train Loss: 0.309||Val Loss: 0.339||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 781||Train Loss: 0.308||Val Loss: 0.342||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 782||Train Loss: 0.306||Val Loss: 0.340||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 783||Train Loss: 0.309||Val Loss: 0.345||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 784||Train Loss: 0.309||Val Loss: 0.345||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 785||Train Loss: 0.309||Val Loss: 0.347||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 786||Train Loss: 0.308||Val Loss: 0.340||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 787||Train Loss: 0.308||Val Loss: 0.344||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 788||Train Loss: 0.307||Val Loss: 0.351||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 789||Train Loss: 0.307||Val Loss: 0.345||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 790||Train Loss: 0.305||Val Loss: 0.351||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 791||Train Loss: 0.305||Val Loss: 0.339||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 792||Train Loss: 0.305||Val Loss: 0.344||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 793||Train Loss: 0.307||Val Loss: 0.351||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 794||Train Loss: 0.304||Val Loss: 0.337||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 795||Train Loss: 0.306||Val Loss: 0.332||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 796||Train Loss: 0.304||Val Loss: 0.342||Val AUC: 0.987||Val AP: 0.987\n",
      "Epoch: 797||Train Loss: 0.304||Val Loss: 0.343||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 798||Train Loss: 0.302||Val Loss: 0.340||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 799||Train Loss: 0.304||Val Loss: 0.337||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 800||Train Loss: 0.301||Val Loss: 0.336||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 801||Train Loss: 0.303||Val Loss: 0.335||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 802||Train Loss: 0.302||Val Loss: 0.335||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 803||Train Loss: 0.301||Val Loss: 0.338||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 804||Train Loss: 0.300||Val Loss: 0.337||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 805||Train Loss: 0.300||Val Loss: 0.336||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 806||Train Loss: 0.301||Val Loss: 0.339||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 807||Train Loss: 0.299||Val Loss: 0.331||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 808||Train Loss: 0.298||Val Loss: 0.326||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 809||Train Loss: 0.300||Val Loss: 0.331||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 810||Train Loss: 0.298||Val Loss: 0.342||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 811||Train Loss: 0.298||Val Loss: 0.346||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 812||Train Loss: 0.299||Val Loss: 0.325||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 813||Train Loss: 0.297||Val Loss: 0.331||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 814||Train Loss: 0.296||Val Loss: 0.338||Val AUC: 0.988||Val AP: 0.987\n",
      "Epoch: 815||Train Loss: 0.296||Val Loss: 0.330||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 816||Train Loss: 0.297||Val Loss: 0.330||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 817||Train Loss: 0.297||Val Loss: 0.325||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 818||Train Loss: 0.294||Val Loss: 0.328||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 819||Train Loss: 0.297||Val Loss: 0.339||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 820||Train Loss: 0.295||Val Loss: 0.334||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 821||Train Loss: 0.294||Val Loss: 0.327||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 822||Train Loss: 0.294||Val Loss: 0.330||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 823||Train Loss: 0.293||Val Loss: 0.326||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 824||Train Loss: 0.292||Val Loss: 0.327||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 825||Train Loss: 0.292||Val Loss: 0.332||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 826||Train Loss: 0.293||Val Loss: 0.327||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 827||Train Loss: 0.290||Val Loss: 0.322||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 828||Train Loss: 0.292||Val Loss: 0.324||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 829||Train Loss: 0.290||Val Loss: 0.326||Val AUC: 0.988||Val AP: 0.988\n",
      "Epoch: 830||Train Loss: 0.290||Val Loss: 0.330||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 831||Train Loss: 0.290||Val Loss: 0.321||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 832||Train Loss: 0.289||Val Loss: 0.323||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 833||Train Loss: 0.290||Val Loss: 0.320||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 834||Train Loss: 0.289||Val Loss: 0.321||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 835||Train Loss: 0.289||Val Loss: 0.323||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 836||Train Loss: 0.289||Val Loss: 0.318||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 837||Train Loss: 0.289||Val Loss: 0.318||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 838||Train Loss: 0.287||Val Loss: 0.320||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 839||Train Loss: 0.287||Val Loss: 0.315||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 840||Train Loss: 0.286||Val Loss: 0.322||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 841||Train Loss: 0.286||Val Loss: 0.324||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 842||Train Loss: 0.286||Val Loss: 0.314||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 843||Train Loss: 0.287||Val Loss: 0.326||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 844||Train Loss: 0.285||Val Loss: 0.323||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 845||Train Loss: 0.286||Val Loss: 0.320||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 846||Train Loss: 0.286||Val Loss: 0.312||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 847||Train Loss: 0.284||Val Loss: 0.315||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 848||Train Loss: 0.285||Val Loss: 0.316||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 849||Train Loss: 0.285||Val Loss: 0.314||Val AUC: 0.989||Val AP: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 850||Train Loss: 0.284||Val Loss: 0.318||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 851||Train Loss: 0.282||Val Loss: 0.310||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 852||Train Loss: 0.284||Val Loss: 0.319||Val AUC: 0.989||Val AP: 0.988\n",
      "Epoch: 853||Train Loss: 0.284||Val Loss: 0.315||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 854||Train Loss: 0.282||Val Loss: 0.315||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 855||Train Loss: 0.281||Val Loss: 0.308||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 856||Train Loss: 0.279||Val Loss: 0.312||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 857||Train Loss: 0.281||Val Loss: 0.322||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 858||Train Loss: 0.282||Val Loss: 0.309||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 859||Train Loss: 0.281||Val Loss: 0.309||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 860||Train Loss: 0.281||Val Loss: 0.312||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 861||Train Loss: 0.279||Val Loss: 0.314||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 862||Train Loss: 0.279||Val Loss: 0.316||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 863||Train Loss: 0.279||Val Loss: 0.313||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 864||Train Loss: 0.279||Val Loss: 0.310||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 865||Train Loss: 0.279||Val Loss: 0.310||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 866||Train Loss: 0.278||Val Loss: 0.304||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 867||Train Loss: 0.277||Val Loss: 0.310||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 868||Train Loss: 0.277||Val Loss: 0.313||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 869||Train Loss: 0.278||Val Loss: 0.301||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 870||Train Loss: 0.276||Val Loss: 0.304||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 871||Train Loss: 0.278||Val Loss: 0.317||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 872||Train Loss: 0.276||Val Loss: 0.316||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 873||Train Loss: 0.275||Val Loss: 0.297||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 874||Train Loss: 0.277||Val Loss: 0.311||Val AUC: 0.989||Val AP: 0.989\n",
      "Epoch: 875||Train Loss: 0.276||Val Loss: 0.304||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 876||Train Loss: 0.275||Val Loss: 0.311||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 877||Train Loss: 0.273||Val Loss: 0.305||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 878||Train Loss: 0.276||Val Loss: 0.305||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 879||Train Loss: 0.273||Val Loss: 0.299||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 880||Train Loss: 0.275||Val Loss: 0.310||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 881||Train Loss: 0.273||Val Loss: 0.304||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 882||Train Loss: 0.272||Val Loss: 0.306||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 883||Train Loss: 0.273||Val Loss: 0.301||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 884||Train Loss: 0.273||Val Loss: 0.301||Val AUC: 0.990||Val AP: 0.989\n",
      "Epoch: 885||Train Loss: 0.272||Val Loss: 0.302||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 886||Train Loss: 0.272||Val Loss: 0.302||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 887||Train Loss: 0.271||Val Loss: 0.303||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 888||Train Loss: 0.272||Val Loss: 0.301||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 889||Train Loss: 0.270||Val Loss: 0.302||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 890||Train Loss: 0.271||Val Loss: 0.299||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 891||Train Loss: 0.270||Val Loss: 0.297||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 892||Train Loss: 0.269||Val Loss: 0.301||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 893||Train Loss: 0.270||Val Loss: 0.298||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 894||Train Loss: 0.269||Val Loss: 0.305||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 895||Train Loss: 0.269||Val Loss: 0.296||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 896||Train Loss: 0.267||Val Loss: 0.296||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 897||Train Loss: 0.271||Val Loss: 0.294||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 898||Train Loss: 0.267||Val Loss: 0.302||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 899||Train Loss: 0.267||Val Loss: 0.294||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 900||Train Loss: 0.267||Val Loss: 0.304||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 901||Train Loss: 0.268||Val Loss: 0.292||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 902||Train Loss: 0.266||Val Loss: 0.305||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 903||Train Loss: 0.268||Val Loss: 0.296||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 904||Train Loss: 0.267||Val Loss: 0.293||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 905||Train Loss: 0.267||Val Loss: 0.297||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 906||Train Loss: 0.265||Val Loss: 0.293||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 907||Train Loss: 0.264||Val Loss: 0.289||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 908||Train Loss: 0.264||Val Loss: 0.296||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 909||Train Loss: 0.264||Val Loss: 0.302||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 910||Train Loss: 0.265||Val Loss: 0.305||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 911||Train Loss: 0.265||Val Loss: 0.291||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 912||Train Loss: 0.264||Val Loss: 0.295||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 913||Train Loss: 0.261||Val Loss: 0.290||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 914||Train Loss: 0.263||Val Loss: 0.293||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 915||Train Loss: 0.262||Val Loss: 0.293||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 916||Train Loss: 0.262||Val Loss: 0.291||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 917||Train Loss: 0.263||Val Loss: 0.293||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 918||Train Loss: 0.261||Val Loss: 0.298||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 919||Train Loss: 0.262||Val Loss: 0.288||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 920||Train Loss: 0.260||Val Loss: 0.289||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 921||Train Loss: 0.260||Val Loss: 0.292||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 922||Train Loss: 0.261||Val Loss: 0.289||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 923||Train Loss: 0.259||Val Loss: 0.294||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 924||Train Loss: 0.261||Val Loss: 0.288||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 925||Train Loss: 0.259||Val Loss: 0.291||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 926||Train Loss: 0.258||Val Loss: 0.285||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 927||Train Loss: 0.258||Val Loss: 0.294||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 928||Train Loss: 0.260||Val Loss: 0.284||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 929||Train Loss: 0.258||Val Loss: 0.291||Val AUC: 0.991||Val AP: 0.990\n",
      "Epoch: 930||Train Loss: 0.257||Val Loss: 0.283||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 931||Train Loss: 0.258||Val Loss: 0.294||Val AUC: 0.990||Val AP: 0.990\n",
      "Epoch: 932||Train Loss: 0.256||Val Loss: 0.289||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 933||Train Loss: 0.255||Val Loss: 0.284||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 934||Train Loss: 0.257||Val Loss: 0.286||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 935||Train Loss: 0.257||Val Loss: 0.286||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 936||Train Loss: 0.259||Val Loss: 0.285||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 937||Train Loss: 0.255||Val Loss: 0.286||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 938||Train Loss: 0.253||Val Loss: 0.283||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 939||Train Loss: 0.255||Val Loss: 0.285||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 940||Train Loss: 0.255||Val Loss: 0.287||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 941||Train Loss: 0.256||Val Loss: 0.281||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 942||Train Loss: 0.254||Val Loss: 0.282||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 943||Train Loss: 0.254||Val Loss: 0.287||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 944||Train Loss: 0.252||Val Loss: 0.284||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 945||Train Loss: 0.254||Val Loss: 0.279||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 946||Train Loss: 0.254||Val Loss: 0.281||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 947||Train Loss: 0.254||Val Loss: 0.280||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 948||Train Loss: 0.254||Val Loss: 0.282||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 949||Train Loss: 0.252||Val Loss: 0.280||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 950||Train Loss: 0.251||Val Loss: 0.282||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 951||Train Loss: 0.252||Val Loss: 0.275||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 952||Train Loss: 0.252||Val Loss: 0.279||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 953||Train Loss: 0.251||Val Loss: 0.279||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 954||Train Loss: 0.251||Val Loss: 0.280||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 955||Train Loss: 0.250||Val Loss: 0.278||Val AUC: 0.991||Val AP: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 956||Train Loss: 0.250||Val Loss: 0.279||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 957||Train Loss: 0.251||Val Loss: 0.286||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 958||Train Loss: 0.250||Val Loss: 0.275||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 959||Train Loss: 0.249||Val Loss: 0.280||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 960||Train Loss: 0.249||Val Loss: 0.285||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 961||Train Loss: 0.248||Val Loss: 0.278||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 962||Train Loss: 0.249||Val Loss: 0.285||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 963||Train Loss: 0.250||Val Loss: 0.276||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 964||Train Loss: 0.249||Val Loss: 0.286||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 965||Train Loss: 0.247||Val Loss: 0.271||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 966||Train Loss: 0.248||Val Loss: 0.279||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 967||Train Loss: 0.250||Val Loss: 0.276||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 968||Train Loss: 0.246||Val Loss: 0.276||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 969||Train Loss: 0.247||Val Loss: 0.277||Val AUC: 0.991||Val AP: 0.991\n",
      "Epoch: 970||Train Loss: 0.246||Val Loss: 0.281||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 971||Train Loss: 0.247||Val Loss: 0.272||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 972||Train Loss: 0.246||Val Loss: 0.277||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 973||Train Loss: 0.245||Val Loss: 0.275||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 974||Train Loss: 0.244||Val Loss: 0.271||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 975||Train Loss: 0.244||Val Loss: 0.269||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 976||Train Loss: 0.245||Val Loss: 0.270||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 977||Train Loss: 0.243||Val Loss: 0.273||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 978||Train Loss: 0.245||Val Loss: 0.271||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 979||Train Loss: 0.244||Val Loss: 0.275||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 980||Train Loss: 0.245||Val Loss: 0.275||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 981||Train Loss: 0.243||Val Loss: 0.267||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 982||Train Loss: 0.244||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 983||Train Loss: 0.242||Val Loss: 0.270||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 984||Train Loss: 0.243||Val Loss: 0.268||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 985||Train Loss: 0.242||Val Loss: 0.272||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 986||Train Loss: 0.242||Val Loss: 0.269||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 987||Train Loss: 0.240||Val Loss: 0.261||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 988||Train Loss: 0.243||Val Loss: 0.269||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 989||Train Loss: 0.242||Val Loss: 0.270||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 990||Train Loss: 0.243||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 991||Train Loss: 0.240||Val Loss: 0.270||Val AUC: 0.992||Val AP: 0.991\n",
      "Epoch: 992||Train Loss: 0.240||Val Loss: 0.264||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 993||Train Loss: 0.241||Val Loss: 0.263||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 994||Train Loss: 0.239||Val Loss: 0.265||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 995||Train Loss: 0.239||Val Loss: 0.271||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 996||Train Loss: 0.241||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 997||Train Loss: 0.241||Val Loss: 0.264||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 998||Train Loss: 0.241||Val Loss: 0.264||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 999||Train Loss: 0.237||Val Loss: 0.261||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1000||Train Loss: 0.240||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1001||Train Loss: 0.238||Val Loss: 0.262||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1002||Train Loss: 0.240||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1003||Train Loss: 0.238||Val Loss: 0.258||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1004||Train Loss: 0.237||Val Loss: 0.272||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1005||Train Loss: 0.235||Val Loss: 0.264||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1006||Train Loss: 0.237||Val Loss: 0.262||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1007||Train Loss: 0.233||Val Loss: 0.267||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1008||Train Loss: 0.238||Val Loss: 0.264||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1009||Train Loss: 0.236||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1010||Train Loss: 0.236||Val Loss: 0.262||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1011||Train Loss: 0.235||Val Loss: 0.259||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1012||Train Loss: 0.236||Val Loss: 0.268||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1013||Train Loss: 0.236||Val Loss: 0.260||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1014||Train Loss: 0.237||Val Loss: 0.258||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1015||Train Loss: 0.235||Val Loss: 0.262||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1016||Train Loss: 0.235||Val Loss: 0.258||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1017||Train Loss: 0.235||Val Loss: 0.260||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1018||Train Loss: 0.234||Val Loss: 0.261||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1019||Train Loss: 0.235||Val Loss: 0.260||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1020||Train Loss: 0.235||Val Loss: 0.256||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1021||Train Loss: 0.234||Val Loss: 0.266||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1022||Train Loss: 0.233||Val Loss: 0.252||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1023||Train Loss: 0.233||Val Loss: 0.260||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1024||Train Loss: 0.233||Val Loss: 0.258||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1025||Train Loss: 0.232||Val Loss: 0.263||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1026||Train Loss: 0.234||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1027||Train Loss: 0.233||Val Loss: 0.257||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1028||Train Loss: 0.232||Val Loss: 0.252||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1029||Train Loss: 0.230||Val Loss: 0.261||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1030||Train Loss: 0.231||Val Loss: 0.259||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1031||Train Loss: 0.232||Val Loss: 0.256||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1032||Train Loss: 0.232||Val Loss: 0.252||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1033||Train Loss: 0.232||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1034||Train Loss: 0.230||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1035||Train Loss: 0.230||Val Loss: 0.251||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1036||Train Loss: 0.231||Val Loss: 0.260||Val AUC: 0.992||Val AP: 0.992\n",
      "Epoch: 1037||Train Loss: 0.228||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1038||Train Loss: 0.230||Val Loss: 0.258||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1039||Train Loss: 0.229||Val Loss: 0.251||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1040||Train Loss: 0.230||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1041||Train Loss: 0.229||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1042||Train Loss: 0.228||Val Loss: 0.253||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1043||Train Loss: 0.227||Val Loss: 0.253||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1044||Train Loss: 0.230||Val Loss: 0.260||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1045||Train Loss: 0.228||Val Loss: 0.251||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1046||Train Loss: 0.226||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1047||Train Loss: 0.230||Val Loss: 0.259||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1048||Train Loss: 0.228||Val Loss: 0.252||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1049||Train Loss: 0.226||Val Loss: 0.257||Val AUC: 0.993||Val AP: 0.992\n",
      "Epoch: 1050||Train Loss: 0.226||Val Loss: 0.257||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1051||Train Loss: 0.226||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1052||Train Loss: 0.227||Val Loss: 0.250||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1053||Train Loss: 0.224||Val Loss: 0.245||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1054||Train Loss: 0.227||Val Loss: 0.249||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1055||Train Loss: 0.225||Val Loss: 0.262||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1056||Train Loss: 0.225||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1057||Train Loss: 0.225||Val Loss: 0.250||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1058||Train Loss: 0.226||Val Loss: 0.254||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1059||Train Loss: 0.226||Val Loss: 0.245||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1060||Train Loss: 0.224||Val Loss: 0.249||Val AUC: 0.993||Val AP: 0.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1061||Train Loss: 0.222||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1062||Train Loss: 0.223||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1063||Train Loss: 0.224||Val Loss: 0.248||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1064||Train Loss: 0.222||Val Loss: 0.250||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1065||Train Loss: 0.222||Val Loss: 0.247||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1066||Train Loss: 0.222||Val Loss: 0.255||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1067||Train Loss: 0.223||Val Loss: 0.244||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1068||Train Loss: 0.222||Val Loss: 0.249||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1069||Train Loss: 0.223||Val Loss: 0.245||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1070||Train Loss: 0.223||Val Loss: 0.244||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1071||Train Loss: 0.222||Val Loss: 0.244||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1072||Train Loss: 0.222||Val Loss: 0.238||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1073||Train Loss: 0.223||Val Loss: 0.245||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1074||Train Loss: 0.222||Val Loss: 0.243||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1075||Train Loss: 0.222||Val Loss: 0.243||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1076||Train Loss: 0.221||Val Loss: 0.242||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1077||Train Loss: 0.219||Val Loss: 0.246||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1078||Train Loss: 0.220||Val Loss: 0.241||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1079||Train Loss: 0.220||Val Loss: 0.242||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1080||Train Loss: 0.221||Val Loss: 0.244||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1081||Train Loss: 0.219||Val Loss: 0.242||Val AUC: 0.994||Val AP: 0.993\n",
      "Epoch: 1082||Train Loss: 0.220||Val Loss: 0.241||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1083||Train Loss: 0.220||Val Loss: 0.247||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1084||Train Loss: 0.221||Val Loss: 0.241||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1085||Train Loss: 0.219||Val Loss: 0.239||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1086||Train Loss: 0.218||Val Loss: 0.239||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1087||Train Loss: 0.219||Val Loss: 0.239||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1088||Train Loss: 0.217||Val Loss: 0.249||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1089||Train Loss: 0.216||Val Loss: 0.244||Val AUC: 0.994||Val AP: 0.993\n",
      "Epoch: 1090||Train Loss: 0.216||Val Loss: 0.246||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1091||Train Loss: 0.219||Val Loss: 0.242||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1092||Train Loss: 0.218||Val Loss: 0.237||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1093||Train Loss: 0.216||Val Loss: 0.237||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1094||Train Loss: 0.216||Val Loss: 0.242||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1095||Train Loss: 0.215||Val Loss: 0.241||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1096||Train Loss: 0.217||Val Loss: 0.240||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1097||Train Loss: 0.215||Val Loss: 0.236||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1098||Train Loss: 0.216||Val Loss: 0.237||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1099||Train Loss: 0.216||Val Loss: 0.237||Val AUC: 0.994||Val AP: 0.993\n",
      "Epoch: 1100||Train Loss: 0.216||Val Loss: 0.237||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1101||Train Loss: 0.216||Val Loss: 0.240||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1102||Train Loss: 0.215||Val Loss: 0.238||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1103||Train Loss: 0.215||Val Loss: 0.239||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1104||Train Loss: 0.213||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1105||Train Loss: 0.211||Val Loss: 0.238||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1106||Train Loss: 0.214||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1107||Train Loss: 0.213||Val Loss: 0.239||Val AUC: 0.993||Val AP: 0.993\n",
      "Epoch: 1108||Train Loss: 0.214||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1109||Train Loss: 0.215||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1110||Train Loss: 0.214||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1111||Train Loss: 0.212||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1112||Train Loss: 0.214||Val Loss: 0.241||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1113||Train Loss: 0.214||Val Loss: 0.234||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1114||Train Loss: 0.211||Val Loss: 0.238||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1115||Train Loss: 0.211||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1116||Train Loss: 0.212||Val Loss: 0.236||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1117||Train Loss: 0.213||Val Loss: 0.236||Val AUC: 0.994||Val AP: 0.993\n",
      "Epoch: 1118||Train Loss: 0.214||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1119||Train Loss: 0.211||Val Loss: 0.234||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1120||Train Loss: 0.211||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1121||Train Loss: 0.210||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1122||Train Loss: 0.212||Val Loss: 0.243||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1123||Train Loss: 0.211||Val Loss: 0.234||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1124||Train Loss: 0.212||Val Loss: 0.230||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1125||Train Loss: 0.211||Val Loss: 0.235||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1126||Train Loss: 0.211||Val Loss: 0.234||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1127||Train Loss: 0.210||Val Loss: 0.237||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1128||Train Loss: 0.209||Val Loss: 0.236||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1129||Train Loss: 0.210||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1130||Train Loss: 0.210||Val Loss: 0.233||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1131||Train Loss: 0.209||Val Loss: 0.240||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1132||Train Loss: 0.209||Val Loss: 0.233||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1133||Train Loss: 0.210||Val Loss: 0.226||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1134||Train Loss: 0.209||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1135||Train Loss: 0.208||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1136||Train Loss: 0.206||Val Loss: 0.230||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1137||Train Loss: 0.208||Val Loss: 0.239||Val AUC: 0.994||Val AP: 0.993\n",
      "Epoch: 1138||Train Loss: 0.208||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1139||Train Loss: 0.207||Val Loss: 0.234||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1140||Train Loss: 0.208||Val Loss: 0.227||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1141||Train Loss: 0.206||Val Loss: 0.227||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1142||Train Loss: 0.207||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1143||Train Loss: 0.208||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1144||Train Loss: 0.208||Val Loss: 0.231||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1145||Train Loss: 0.208||Val Loss: 0.224||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1146||Train Loss: 0.205||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1147||Train Loss: 0.206||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1148||Train Loss: 0.205||Val Loss: 0.224||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1149||Train Loss: 0.205||Val Loss: 0.232||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1150||Train Loss: 0.206||Val Loss: 0.227||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1151||Train Loss: 0.204||Val Loss: 0.230||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1152||Train Loss: 0.205||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1153||Train Loss: 0.204||Val Loss: 0.226||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1154||Train Loss: 0.205||Val Loss: 0.223||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1155||Train Loss: 0.204||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1156||Train Loss: 0.204||Val Loss: 0.230||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1157||Train Loss: 0.204||Val Loss: 0.224||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1158||Train Loss: 0.203||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1159||Train Loss: 0.204||Val Loss: 0.220||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1160||Train Loss: 0.204||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1161||Train Loss: 0.204||Val Loss: 0.229||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1162||Train Loss: 0.204||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1163||Train Loss: 0.204||Val Loss: 0.220||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1164||Train Loss: 0.202||Val Loss: 0.217||Val AUC: 0.994||Val AP: 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1165||Train Loss: 0.202||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1166||Train Loss: 0.201||Val Loss: 0.223||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1167||Train Loss: 0.205||Val Loss: 0.222||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1168||Train Loss: 0.203||Val Loss: 0.222||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1169||Train Loss: 0.204||Val Loss: 0.222||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1170||Train Loss: 0.201||Val Loss: 0.221||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1171||Train Loss: 0.204||Val Loss: 0.222||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1172||Train Loss: 0.203||Val Loss: 0.223||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1173||Train Loss: 0.202||Val Loss: 0.224||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1174||Train Loss: 0.201||Val Loss: 0.226||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1175||Train Loss: 0.201||Val Loss: 0.228||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1176||Train Loss: 0.201||Val Loss: 0.224||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1177||Train Loss: 0.200||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1178||Train Loss: 0.201||Val Loss: 0.221||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1179||Train Loss: 0.200||Val Loss: 0.218||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1180||Train Loss: 0.201||Val Loss: 0.218||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1181||Train Loss: 0.200||Val Loss: 0.221||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1182||Train Loss: 0.199||Val Loss: 0.226||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1183||Train Loss: 0.200||Val Loss: 0.221||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1184||Train Loss: 0.199||Val Loss: 0.222||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1185||Train Loss: 0.200||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1186||Train Loss: 0.199||Val Loss: 0.218||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1187||Train Loss: 0.198||Val Loss: 0.220||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1188||Train Loss: 0.199||Val Loss: 0.217||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1189||Train Loss: 0.198||Val Loss: 0.222||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1190||Train Loss: 0.198||Val Loss: 0.222||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1191||Train Loss: 0.199||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1192||Train Loss: 0.199||Val Loss: 0.225||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1193||Train Loss: 0.198||Val Loss: 0.219||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1194||Train Loss: 0.198||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1195||Train Loss: 0.197||Val Loss: 0.222||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1196||Train Loss: 0.196||Val Loss: 0.219||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1197||Train Loss: 0.197||Val Loss: 0.220||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1198||Train Loss: 0.197||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1199||Train Loss: 0.196||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1200||Train Loss: 0.196||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1201||Train Loss: 0.198||Val Loss: 0.219||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1202||Train Loss: 0.198||Val Loss: 0.213||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1203||Train Loss: 0.197||Val Loss: 0.220||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1204||Train Loss: 0.196||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1205||Train Loss: 0.194||Val Loss: 0.213||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1206||Train Loss: 0.195||Val Loss: 0.220||Val AUC: 0.994||Val AP: 0.994\n",
      "Epoch: 1207||Train Loss: 0.195||Val Loss: 0.219||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1208||Train Loss: 0.196||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1209||Train Loss: 0.194||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1210||Train Loss: 0.194||Val Loss: 0.216||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1211||Train Loss: 0.194||Val Loss: 0.218||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1212||Train Loss: 0.195||Val Loss: 0.221||Val AUC: 0.995||Val AP: 0.994\n",
      "Epoch: 1213||Train Loss: 0.194||Val Loss: 0.213||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1214||Train Loss: 0.195||Val Loss: 0.211||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1215||Train Loss: 0.194||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1216||Train Loss: 0.194||Val Loss: 0.210||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1217||Train Loss: 0.193||Val Loss: 0.216||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1218||Train Loss: 0.194||Val Loss: 0.213||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1219||Train Loss: 0.192||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1220||Train Loss: 0.194||Val Loss: 0.216||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1221||Train Loss: 0.192||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1222||Train Loss: 0.192||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1223||Train Loss: 0.192||Val Loss: 0.214||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1224||Train Loss: 0.193||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1225||Train Loss: 0.193||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1226||Train Loss: 0.194||Val Loss: 0.217||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1227||Train Loss: 0.193||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1228||Train Loss: 0.191||Val Loss: 0.215||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1229||Train Loss: 0.192||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1230||Train Loss: 0.191||Val Loss: 0.216||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1231||Train Loss: 0.193||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1232||Train Loss: 0.191||Val Loss: 0.218||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1233||Train Loss: 0.191||Val Loss: 0.211||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1234||Train Loss: 0.191||Val Loss: 0.205||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1235||Train Loss: 0.191||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1236||Train Loss: 0.190||Val Loss: 0.210||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1237||Train Loss: 0.190||Val Loss: 0.205||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1238||Train Loss: 0.190||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1239||Train Loss: 0.191||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1240||Train Loss: 0.190||Val Loss: 0.206||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1241||Train Loss: 0.190||Val Loss: 0.213||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1242||Train Loss: 0.190||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1243||Train Loss: 0.191||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1244||Train Loss: 0.191||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1245||Train Loss: 0.189||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1246||Train Loss: 0.190||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1247||Train Loss: 0.189||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1248||Train Loss: 0.190||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1249||Train Loss: 0.190||Val Loss: 0.205||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1250||Train Loss: 0.189||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1251||Train Loss: 0.188||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1252||Train Loss: 0.189||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1253||Train Loss: 0.190||Val Loss: 0.206||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1254||Train Loss: 0.190||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1255||Train Loss: 0.187||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1256||Train Loss: 0.187||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1257||Train Loss: 0.187||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1258||Train Loss: 0.187||Val Loss: 0.206||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1259||Train Loss: 0.186||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1260||Train Loss: 0.189||Val Loss: 0.206||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1261||Train Loss: 0.187||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1262||Train Loss: 0.187||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1263||Train Loss: 0.188||Val Loss: 0.204||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1264||Train Loss: 0.187||Val Loss: 0.211||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1265||Train Loss: 0.187||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1266||Train Loss: 0.188||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1267||Train Loss: 0.187||Val Loss: 0.206||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1268||Train Loss: 0.187||Val Loss: 0.203||Val AUC: 0.995||Val AP: 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1269||Train Loss: 0.186||Val Loss: 0.204||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1270||Train Loss: 0.186||Val Loss: 0.204||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1271||Train Loss: 0.185||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1272||Train Loss: 0.187||Val Loss: 0.204||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1273||Train Loss: 0.187||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1274||Train Loss: 0.184||Val Loss: 0.203||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1275||Train Loss: 0.184||Val Loss: 0.205||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1276||Train Loss: 0.185||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1277||Train Loss: 0.184||Val Loss: 0.197||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1278||Train Loss: 0.185||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1279||Train Loss: 0.183||Val Loss: 0.205||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1280||Train Loss: 0.186||Val Loss: 0.203||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1281||Train Loss: 0.184||Val Loss: 0.203||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1282||Train Loss: 0.185||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1283||Train Loss: 0.184||Val Loss: 0.210||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1284||Train Loss: 0.183||Val Loss: 0.201||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1285||Train Loss: 0.184||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1286||Train Loss: 0.184||Val Loss: 0.204||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1287||Train Loss: 0.184||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1288||Train Loss: 0.183||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1289||Train Loss: 0.184||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1290||Train Loss: 0.182||Val Loss: 0.201||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1291||Train Loss: 0.182||Val Loss: 0.212||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1292||Train Loss: 0.182||Val Loss: 0.198||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1293||Train Loss: 0.182||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1294||Train Loss: 0.182||Val Loss: 0.201||Val AUC: 0.996||Val AP: 0.995\n",
      "Epoch: 1295||Train Loss: 0.182||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1296||Train Loss: 0.182||Val Loss: 0.200||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1297||Train Loss: 0.182||Val Loss: 0.201||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1298||Train Loss: 0.182||Val Loss: 0.197||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1299||Train Loss: 0.181||Val Loss: 0.195||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1300||Train Loss: 0.183||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1301||Train Loss: 0.182||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1302||Train Loss: 0.182||Val Loss: 0.200||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1303||Train Loss: 0.181||Val Loss: 0.209||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1304||Train Loss: 0.183||Val Loss: 0.197||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1305||Train Loss: 0.181||Val Loss: 0.207||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1306||Train Loss: 0.182||Val Loss: 0.196||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1307||Train Loss: 0.180||Val Loss: 0.199||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1308||Train Loss: 0.180||Val Loss: 0.196||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1309||Train Loss: 0.180||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1310||Train Loss: 0.180||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1311||Train Loss: 0.181||Val Loss: 0.198||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1312||Train Loss: 0.181||Val Loss: 0.197||Val AUC: 0.996||Val AP: 0.995\n",
      "Epoch: 1313||Train Loss: 0.180||Val Loss: 0.197||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1314||Train Loss: 0.180||Val Loss: 0.208||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1315||Train Loss: 0.180||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1316||Train Loss: 0.179||Val Loss: 0.200||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1317||Train Loss: 0.179||Val Loss: 0.200||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1318||Train Loss: 0.179||Val Loss: 0.195||Val AUC: 0.996||Val AP: 0.995\n",
      "Epoch: 1319||Train Loss: 0.180||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1320||Train Loss: 0.179||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1321||Train Loss: 0.179||Val Loss: 0.205||Val AUC: 0.996||Val AP: 0.995\n",
      "Epoch: 1322||Train Loss: 0.178||Val Loss: 0.194||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1323||Train Loss: 0.179||Val Loss: 0.203||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1324||Train Loss: 0.180||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1325||Train Loss: 0.179||Val Loss: 0.197||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1326||Train Loss: 0.178||Val Loss: 0.197||Val AUC: 0.996||Val AP: 0.995\n",
      "Epoch: 1327||Train Loss: 0.179||Val Loss: 0.195||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1328||Train Loss: 0.179||Val Loss: 0.194||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1329||Train Loss: 0.178||Val Loss: 0.202||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1330||Train Loss: 0.177||Val Loss: 0.195||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1331||Train Loss: 0.179||Val Loss: 0.193||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1332||Train Loss: 0.177||Val Loss: 0.195||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1333||Train Loss: 0.178||Val Loss: 0.198||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1334||Train Loss: 0.176||Val Loss: 0.195||Val AUC: 0.995||Val AP: 0.995\n",
      "Epoch: 1335||Train Loss: 0.177||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1336||Train Loss: 0.178||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1337||Train Loss: 0.177||Val Loss: 0.194||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1338||Train Loss: 0.176||Val Loss: 0.196||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1339||Train Loss: 0.177||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1340||Train Loss: 0.177||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1341||Train Loss: 0.177||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1342||Train Loss: 0.176||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1343||Train Loss: 0.177||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1344||Train Loss: 0.174||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1345||Train Loss: 0.177||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1346||Train Loss: 0.175||Val Loss: 0.197||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1347||Train Loss: 0.176||Val Loss: 0.202||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1348||Train Loss: 0.175||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1349||Train Loss: 0.176||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1350||Train Loss: 0.175||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1351||Train Loss: 0.174||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1352||Train Loss: 0.174||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1353||Train Loss: 0.175||Val Loss: 0.196||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1354||Train Loss: 0.175||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1355||Train Loss: 0.173||Val Loss: 0.195||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1356||Train Loss: 0.175||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1357||Train Loss: 0.174||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1358||Train Loss: 0.174||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1359||Train Loss: 0.175||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1360||Train Loss: 0.174||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1361||Train Loss: 0.174||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1362||Train Loss: 0.175||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1363||Train Loss: 0.173||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1364||Train Loss: 0.173||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1365||Train Loss: 0.173||Val Loss: 0.190||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1366||Train Loss: 0.172||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1367||Train Loss: 0.173||Val Loss: 0.196||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1368||Train Loss: 0.172||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1369||Train Loss: 0.172||Val Loss: 0.190||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1370||Train Loss: 0.173||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1371||Train Loss: 0.172||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1372||Train Loss: 0.174||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1373||Train Loss: 0.173||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1374||Train Loss: 0.173||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1375||Train Loss: 0.170||Val Loss: 0.193||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1376||Train Loss: 0.172||Val Loss: 0.191||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1377||Train Loss: 0.174||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1378||Train Loss: 0.173||Val Loss: 0.194||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1379||Train Loss: 0.173||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1380||Train Loss: 0.170||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1381||Train Loss: 0.170||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1382||Train Loss: 0.171||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1383||Train Loss: 0.171||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1384||Train Loss: 0.169||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1385||Train Loss: 0.171||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1386||Train Loss: 0.169||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1387||Train Loss: 0.171||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1388||Train Loss: 0.171||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1389||Train Loss: 0.172||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1390||Train Loss: 0.170||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1391||Train Loss: 0.168||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1392||Train Loss: 0.170||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1393||Train Loss: 0.171||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1394||Train Loss: 0.170||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1395||Train Loss: 0.169||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1396||Train Loss: 0.168||Val Loss: 0.188||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1397||Train Loss: 0.169||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1398||Train Loss: 0.170||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1399||Train Loss: 0.168||Val Loss: 0.190||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1400||Train Loss: 0.168||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1401||Train Loss: 0.171||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1402||Train Loss: 0.170||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1403||Train Loss: 0.169||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1404||Train Loss: 0.168||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1405||Train Loss: 0.168||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1406||Train Loss: 0.167||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1407||Train Loss: 0.168||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1408||Train Loss: 0.168||Val Loss: 0.184||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1409||Train Loss: 0.168||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1410||Train Loss: 0.167||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1411||Train Loss: 0.168||Val Loss: 0.184||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1412||Train Loss: 0.168||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1413||Train Loss: 0.167||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1414||Train Loss: 0.168||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1415||Train Loss: 0.167||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1416||Train Loss: 0.166||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1417||Train Loss: 0.167||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1418||Train Loss: 0.167||Val Loss: 0.187||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1419||Train Loss: 0.168||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1420||Train Loss: 0.167||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1421||Train Loss: 0.166||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1422||Train Loss: 0.166||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1423||Train Loss: 0.166||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1424||Train Loss: 0.165||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1425||Train Loss: 0.166||Val Loss: 0.192||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1426||Train Loss: 0.166||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1427||Train Loss: 0.167||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1428||Train Loss: 0.165||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1429||Train Loss: 0.164||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1430||Train Loss: 0.165||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1431||Train Loss: 0.167||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1432||Train Loss: 0.165||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1433||Train Loss: 0.165||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1434||Train Loss: 0.166||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1435||Train Loss: 0.166||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1436||Train Loss: 0.166||Val Loss: 0.183||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1437||Train Loss: 0.164||Val Loss: 0.185||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1438||Train Loss: 0.166||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1439||Train Loss: 0.164||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1440||Train Loss: 0.164||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1441||Train Loss: 0.163||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1442||Train Loss: 0.165||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1443||Train Loss: 0.164||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1444||Train Loss: 0.164||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1445||Train Loss: 0.165||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1446||Train Loss: 0.164||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1447||Train Loss: 0.165||Val Loss: 0.186||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1448||Train Loss: 0.163||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1449||Train Loss: 0.164||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1450||Train Loss: 0.163||Val Loss: 0.175||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1451||Train Loss: 0.163||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1452||Train Loss: 0.162||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1453||Train Loss: 0.164||Val Loss: 0.189||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1454||Train Loss: 0.164||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1455||Train Loss: 0.164||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1456||Train Loss: 0.161||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1457||Train Loss: 0.163||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1458||Train Loss: 0.162||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1459||Train Loss: 0.162||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1460||Train Loss: 0.163||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1461||Train Loss: 0.162||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1462||Train Loss: 0.163||Val Loss: 0.175||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1463||Train Loss: 0.162||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1464||Train Loss: 0.163||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1465||Train Loss: 0.162||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1466||Train Loss: 0.162||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1467||Train Loss: 0.161||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1468||Train Loss: 0.162||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1469||Train Loss: 0.162||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1470||Train Loss: 0.162||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1471||Train Loss: 0.161||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1472||Train Loss: 0.161||Val Loss: 0.178||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1473||Train Loss: 0.163||Val Loss: 0.175||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1474||Train Loss: 0.163||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1475||Train Loss: 0.159||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1476||Train Loss: 0.160||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1477||Train Loss: 0.160||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1478||Train Loss: 0.162||Val Loss: 0.181||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1479||Train Loss: 0.160||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1480||Train Loss: 0.159||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1481||Train Loss: 0.161||Val Loss: 0.182||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1482||Train Loss: 0.161||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1483||Train Loss: 0.160||Val Loss: 0.172||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1484||Train Loss: 0.160||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1485||Train Loss: 0.159||Val Loss: 0.175||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1486||Train Loss: 0.160||Val Loss: 0.180||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1487||Train Loss: 0.160||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1488||Train Loss: 0.160||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1489||Train Loss: 0.159||Val Loss: 0.169||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1490||Train Loss: 0.159||Val Loss: 0.180||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1491||Train Loss: 0.161||Val Loss: 0.171||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1492||Train Loss: 0.162||Val Loss: 0.172||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1493||Train Loss: 0.159||Val Loss: 0.175||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1494||Train Loss: 0.161||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1495||Train Loss: 0.159||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1496||Train Loss: 0.159||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1497||Train Loss: 0.160||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1498||Train Loss: 0.160||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1499||Train Loss: 0.159||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1500||Train Loss: 0.159||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1501||Train Loss: 0.160||Val Loss: 0.170||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1502||Train Loss: 0.160||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1503||Train Loss: 0.158||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1504||Train Loss: 0.157||Val Loss: 0.170||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1505||Train Loss: 0.159||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1506||Train Loss: 0.160||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1507||Train Loss: 0.157||Val Loss: 0.169||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1508||Train Loss: 0.160||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1509||Train Loss: 0.158||Val Loss: 0.174||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1510||Train Loss: 0.159||Val Loss: 0.172||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1511||Train Loss: 0.157||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1512||Train Loss: 0.157||Val Loss: 0.179||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1513||Train Loss: 0.158||Val Loss: 0.173||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1514||Train Loss: 0.158||Val Loss: 0.174||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1515||Train Loss: 0.158||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1516||Train Loss: 0.157||Val Loss: 0.176||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1517||Train Loss: 0.157||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1518||Train Loss: 0.157||Val Loss: 0.176||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1519||Train Loss: 0.157||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1520||Train Loss: 0.157||Val Loss: 0.173||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1521||Train Loss: 0.156||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1522||Train Loss: 0.155||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1523||Train Loss: 0.156||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1524||Train Loss: 0.158||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1525||Train Loss: 0.156||Val Loss: 0.169||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1526||Train Loss: 0.157||Val Loss: 0.171||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1527||Train Loss: 0.157||Val Loss: 0.174||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1528||Train Loss: 0.155||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1529||Train Loss: 0.156||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1530||Train Loss: 0.155||Val Loss: 0.171||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1531||Train Loss: 0.156||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1532||Train Loss: 0.155||Val Loss: 0.171||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1533||Train Loss: 0.156||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1534||Train Loss: 0.155||Val Loss: 0.174||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1535||Train Loss: 0.155||Val Loss: 0.174||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1536||Train Loss: 0.156||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1537||Train Loss: 0.153||Val Loss: 0.177||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1538||Train Loss: 0.155||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1539||Train Loss: 0.155||Val Loss: 0.173||Val AUC: 0.996||Val AP: 0.996\n",
      "Epoch: 1540||Train Loss: 0.154||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1541||Train Loss: 0.154||Val Loss: 0.176||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1542||Train Loss: 0.154||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1543||Train Loss: 0.155||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1544||Train Loss: 0.156||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1545||Train Loss: 0.153||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1546||Train Loss: 0.155||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.996\n",
      "Epoch: 1547||Train Loss: 0.155||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1548||Train Loss: 0.154||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1549||Train Loss: 0.153||Val Loss: 0.173||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1550||Train Loss: 0.154||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1551||Train Loss: 0.154||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1552||Train Loss: 0.154||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1553||Train Loss: 0.154||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1554||Train Loss: 0.153||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1555||Train Loss: 0.155||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1556||Train Loss: 0.153||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1557||Train Loss: 0.152||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1558||Train Loss: 0.152||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1559||Train Loss: 0.155||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1560||Train Loss: 0.154||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1561||Train Loss: 0.153||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1562||Train Loss: 0.154||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1563||Train Loss: 0.153||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1564||Train Loss: 0.152||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1565||Train Loss: 0.153||Val Loss: 0.175||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1566||Train Loss: 0.153||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1567||Train Loss: 0.153||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1568||Train Loss: 0.152||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1569||Train Loss: 0.153||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1570||Train Loss: 0.151||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1571||Train Loss: 0.152||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1572||Train Loss: 0.152||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1573||Train Loss: 0.153||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1574||Train Loss: 0.153||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1575||Train Loss: 0.152||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1576||Train Loss: 0.152||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1577||Train Loss: 0.150||Val Loss: 0.177||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1578||Train Loss: 0.150||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1579||Train Loss: 0.153||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1580||Train Loss: 0.152||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1581||Train Loss: 0.152||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1582||Train Loss: 0.150||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1583||Train Loss: 0.152||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1584||Train Loss: 0.151||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1585||Train Loss: 0.151||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1586||Train Loss: 0.151||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1587||Train Loss: 0.151||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1588||Train Loss: 0.151||Val Loss: 0.172||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1589||Train Loss: 0.151||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1590||Train Loss: 0.150||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1591||Train Loss: 0.150||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1592||Train Loss: 0.149||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1593||Train Loss: 0.150||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1594||Train Loss: 0.149||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1595||Train Loss: 0.152||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1596||Train Loss: 0.152||Val Loss: 0.168||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1597||Train Loss: 0.150||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1598||Train Loss: 0.149||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1599||Train Loss: 0.149||Val Loss: 0.173||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1600||Train Loss: 0.149||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1601||Train Loss: 0.151||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1602||Train Loss: 0.149||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1603||Train Loss: 0.150||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1604||Train Loss: 0.149||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1605||Train Loss: 0.148||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1606||Train Loss: 0.148||Val Loss: 0.169||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1607||Train Loss: 0.149||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1608||Train Loss: 0.149||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1609||Train Loss: 0.150||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1610||Train Loss: 0.149||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1611||Train Loss: 0.152||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1612||Train Loss: 0.149||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1613||Train Loss: 0.150||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1614||Train Loss: 0.149||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1615||Train Loss: 0.148||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1616||Train Loss: 0.148||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1617||Train Loss: 0.147||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1618||Train Loss: 0.148||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1619||Train Loss: 0.148||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1620||Train Loss: 0.148||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1621||Train Loss: 0.147||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1622||Train Loss: 0.147||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1623||Train Loss: 0.147||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1624||Train Loss: 0.148||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1625||Train Loss: 0.149||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1626||Train Loss: 0.148||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1627||Train Loss: 0.147||Val Loss: 0.170||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1628||Train Loss: 0.148||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1629||Train Loss: 0.149||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1630||Train Loss: 0.149||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1631||Train Loss: 0.146||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1632||Train Loss: 0.147||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1633||Train Loss: 0.147||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1634||Train Loss: 0.147||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1635||Train Loss: 0.148||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1636||Train Loss: 0.148||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1637||Train Loss: 0.147||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1638||Train Loss: 0.148||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1639||Train Loss: 0.148||Val Loss: 0.164||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1640||Train Loss: 0.146||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1641||Train Loss: 0.147||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1642||Train Loss: 0.146||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1643||Train Loss: 0.148||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1644||Train Loss: 0.146||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1645||Train Loss: 0.147||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1646||Train Loss: 0.147||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1647||Train Loss: 0.147||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1648||Train Loss: 0.146||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1649||Train Loss: 0.146||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1650||Train Loss: 0.145||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1651||Train Loss: 0.146||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1652||Train Loss: 0.146||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1653||Train Loss: 0.145||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1654||Train Loss: 0.146||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1655||Train Loss: 0.146||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1656||Train Loss: 0.144||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1657||Train Loss: 0.145||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1658||Train Loss: 0.146||Val Loss: 0.165||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1659||Train Loss: 0.146||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1660||Train Loss: 0.147||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1661||Train Loss: 0.145||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1662||Train Loss: 0.146||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1663||Train Loss: 0.145||Val Loss: 0.167||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1664||Train Loss: 0.145||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1665||Train Loss: 0.145||Val Loss: 0.166||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1666||Train Loss: 0.147||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1667||Train Loss: 0.144||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1668||Train Loss: 0.145||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1669||Train Loss: 0.145||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1670||Train Loss: 0.145||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1671||Train Loss: 0.145||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1672||Train Loss: 0.144||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1673||Train Loss: 0.144||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1674||Train Loss: 0.144||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1675||Train Loss: 0.146||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1676||Train Loss: 0.143||Val Loss: 0.163||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1677||Train Loss: 0.144||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1678||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1679||Train Loss: 0.143||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1680||Train Loss: 0.144||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1681||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1682||Train Loss: 0.142||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1683||Train Loss: 0.143||Val Loss: 0.159||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1684||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1685||Train Loss: 0.143||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1686||Train Loss: 0.144||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1687||Train Loss: 0.144||Val Loss: 0.160||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1688||Train Loss: 0.143||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1689||Train Loss: 0.142||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1690||Train Loss: 0.143||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1691||Train Loss: 0.142||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1692||Train Loss: 0.142||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1693||Train Loss: 0.142||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1694||Train Loss: 0.142||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1695||Train Loss: 0.142||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1696||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1697||Train Loss: 0.142||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1698||Train Loss: 0.142||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1699||Train Loss: 0.143||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1700||Train Loss: 0.143||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1701||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1702||Train Loss: 0.143||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1703||Train Loss: 0.141||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1704||Train Loss: 0.141||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1705||Train Loss: 0.141||Val Loss: 0.158||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1706||Train Loss: 0.142||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1707||Train Loss: 0.143||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1708||Train Loss: 0.142||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1709||Train Loss: 0.142||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1710||Train Loss: 0.142||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1711||Train Loss: 0.142||Val Loss: 0.161||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1712||Train Loss: 0.142||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1713||Train Loss: 0.144||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1714||Train Loss: 0.140||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1715||Train Loss: 0.141||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1716||Train Loss: 0.141||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1717||Train Loss: 0.141||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1718||Train Loss: 0.142||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1719||Train Loss: 0.141||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1720||Train Loss: 0.140||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1721||Train Loss: 0.141||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1722||Train Loss: 0.141||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1723||Train Loss: 0.140||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1724||Train Loss: 0.141||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1725||Train Loss: 0.140||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1726||Train Loss: 0.140||Val Loss: 0.162||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1727||Train Loss: 0.139||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1728||Train Loss: 0.138||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1729||Train Loss: 0.138||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1730||Train Loss: 0.139||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1731||Train Loss: 0.140||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1732||Train Loss: 0.138||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1733||Train Loss: 0.141||Val Loss: 0.155||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1734||Train Loss: 0.140||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1735||Train Loss: 0.138||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1736||Train Loss: 0.140||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1737||Train Loss: 0.140||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1738||Train Loss: 0.138||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1739||Train Loss: 0.139||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1740||Train Loss: 0.140||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1741||Train Loss: 0.138||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1742||Train Loss: 0.140||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1743||Train Loss: 0.139||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1744||Train Loss: 0.141||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1745||Train Loss: 0.138||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1746||Train Loss: 0.138||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1747||Train Loss: 0.139||Val Loss: 0.157||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1748||Train Loss: 0.140||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1749||Train Loss: 0.141||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1750||Train Loss: 0.138||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1751||Train Loss: 0.139||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1752||Train Loss: 0.139||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1753||Train Loss: 0.139||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1754||Train Loss: 0.139||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1755||Train Loss: 0.139||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1756||Train Loss: 0.139||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1757||Train Loss: 0.139||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1758||Train Loss: 0.137||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1759||Train Loss: 0.138||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1760||Train Loss: 0.138||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1761||Train Loss: 0.139||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1762||Train Loss: 0.138||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1763||Train Loss: 0.139||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1764||Train Loss: 0.137||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1765||Train Loss: 0.138||Val Loss: 0.156||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1766||Train Loss: 0.139||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1767||Train Loss: 0.136||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1768||Train Loss: 0.138||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1769||Train Loss: 0.137||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1770||Train Loss: 0.138||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1771||Train Loss: 0.137||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1772||Train Loss: 0.137||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1773||Train Loss: 0.138||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1774||Train Loss: 0.136||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1775||Train Loss: 0.137||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1776||Train Loss: 0.136||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1777||Train Loss: 0.136||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1778||Train Loss: 0.137||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1779||Train Loss: 0.135||Val Loss: 0.143||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1780||Train Loss: 0.138||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1781||Train Loss: 0.136||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1782||Train Loss: 0.136||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1783||Train Loss: 0.137||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1784||Train Loss: 0.137||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1785||Train Loss: 0.138||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1786||Train Loss: 0.137||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1787||Train Loss: 0.137||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1788||Train Loss: 0.136||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1789||Train Loss: 0.136||Val Loss: 0.152||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1790||Train Loss: 0.137||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1791||Train Loss: 0.138||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1792||Train Loss: 0.137||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1793||Train Loss: 0.137||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1794||Train Loss: 0.136||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1795||Train Loss: 0.136||Val Loss: 0.151||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1796||Train Loss: 0.137||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1797||Train Loss: 0.137||Val Loss: 0.144||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1798||Train Loss: 0.135||Val Loss: 0.149||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1799||Train Loss: 0.136||Val Loss: 0.144||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1800||Train Loss: 0.135||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1801||Train Loss: 0.137||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1802||Train Loss: 0.135||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1803||Train Loss: 0.135||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1804||Train Loss: 0.136||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1805||Train Loss: 0.136||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1806||Train Loss: 0.134||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1807||Train Loss: 0.135||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1808||Train Loss: 0.134||Val Loss: 0.147||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1809||Train Loss: 0.135||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1810||Train Loss: 0.134||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1811||Train Loss: 0.134||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1812||Train Loss: 0.137||Val Loss: 0.144||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1813||Train Loss: 0.135||Val Loss: 0.150||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1814||Train Loss: 0.135||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1815||Train Loss: 0.134||Val Loss: 0.148||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1816||Train Loss: 0.135||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1817||Train Loss: 0.136||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1818||Train Loss: 0.134||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1819||Train Loss: 0.135||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1820||Train Loss: 0.135||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1821||Train Loss: 0.134||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1822||Train Loss: 0.135||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1823||Train Loss: 0.134||Val Loss: 0.142||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1824||Train Loss: 0.135||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1825||Train Loss: 0.133||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1826||Train Loss: 0.132||Val Loss: 0.143||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1827||Train Loss: 0.134||Val Loss: 0.153||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1828||Train Loss: 0.134||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1829||Train Loss: 0.135||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1830||Train Loss: 0.135||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1831||Train Loss: 0.133||Val Loss: 0.154||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1832||Train Loss: 0.133||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1833||Train Loss: 0.133||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1834||Train Loss: 0.134||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1835||Train Loss: 0.133||Val Loss: 0.142||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1836||Train Loss: 0.133||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1837||Train Loss: 0.133||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1838||Train Loss: 0.135||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1839||Train Loss: 0.134||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1840||Train Loss: 0.133||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1841||Train Loss: 0.133||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1842||Train Loss: 0.133||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1843||Train Loss: 0.134||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1844||Train Loss: 0.133||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1845||Train Loss: 0.134||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1846||Train Loss: 0.132||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1847||Train Loss: 0.132||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1848||Train Loss: 0.134||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1849||Train Loss: 0.132||Val Loss: 0.142||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1850||Train Loss: 0.132||Val Loss: 0.149||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1851||Train Loss: 0.133||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1852||Train Loss: 0.131||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1853||Train Loss: 0.132||Val Loss: 0.144||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1854||Train Loss: 0.133||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1855||Train Loss: 0.131||Val Loss: 0.146||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1856||Train Loss: 0.133||Val Loss: 0.147||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1857||Train Loss: 0.131||Val Loss: 0.150||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1858||Train Loss: 0.132||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1859||Train Loss: 0.132||Val Loss: 0.146||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1860||Train Loss: 0.132||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1861||Train Loss: 0.132||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1862||Train Loss: 0.133||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1863||Train Loss: 0.133||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1864||Train Loss: 0.131||Val Loss: 0.149||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1865||Train Loss: 0.131||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1866||Train Loss: 0.132||Val Loss: 0.145||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1867||Train Loss: 0.130||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1868||Train Loss: 0.133||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1869||Train Loss: 0.132||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1870||Train Loss: 0.132||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1871||Train Loss: 0.132||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1872||Train Loss: 0.132||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1873||Train Loss: 0.130||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1874||Train Loss: 0.131||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1875||Train Loss: 0.131||Val Loss: 0.147||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1876||Train Loss: 0.129||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1877||Train Loss: 0.130||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1878||Train Loss: 0.131||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.997\n",
      "Epoch: 1879||Train Loss: 0.133||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1880||Train Loss: 0.132||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1881||Train Loss: 0.131||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1882||Train Loss: 0.131||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1883||Train Loss: 0.130||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1884||Train Loss: 0.131||Val Loss: 0.146||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1885||Train Loss: 0.131||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1886||Train Loss: 0.131||Val Loss: 0.146||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1887||Train Loss: 0.132||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1888||Train Loss: 0.130||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1889||Train Loss: 0.129||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1890||Train Loss: 0.128||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1891||Train Loss: 0.130||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1892||Train Loss: 0.129||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1893||Train Loss: 0.131||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1894||Train Loss: 0.129||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1895||Train Loss: 0.130||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1896||Train Loss: 0.129||Val Loss: 0.144||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1897||Train Loss: 0.130||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1898||Train Loss: 0.129||Val Loss: 0.147||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1899||Train Loss: 0.131||Val Loss: 0.144||Val AUC: 0.997||Val AP: 0.997\n",
      "Epoch: 1900||Train Loss: 0.129||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1901||Train Loss: 0.130||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1902||Train Loss: 0.129||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1903||Train Loss: 0.128||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1904||Train Loss: 0.131||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1905||Train Loss: 0.130||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1906||Train Loss: 0.130||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1907||Train Loss: 0.128||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1908||Train Loss: 0.130||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1909||Train Loss: 0.129||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1910||Train Loss: 0.129||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1911||Train Loss: 0.129||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1912||Train Loss: 0.129||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1913||Train Loss: 0.128||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1914||Train Loss: 0.128||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1915||Train Loss: 0.130||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1916||Train Loss: 0.129||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1917||Train Loss: 0.130||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1918||Train Loss: 0.128||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1919||Train Loss: 0.128||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1920||Train Loss: 0.129||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1921||Train Loss: 0.128||Val Loss: 0.146||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1922||Train Loss: 0.128||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1923||Train Loss: 0.128||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1924||Train Loss: 0.128||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1925||Train Loss: 0.129||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1926||Train Loss: 0.129||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1927||Train Loss: 0.130||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1928||Train Loss: 0.129||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1929||Train Loss: 0.129||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1930||Train Loss: 0.128||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1931||Train Loss: 0.128||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1932||Train Loss: 0.128||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1933||Train Loss: 0.129||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1934||Train Loss: 0.128||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1935||Train Loss: 0.129||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1936||Train Loss: 0.127||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1937||Train Loss: 0.129||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1938||Train Loss: 0.127||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1939||Train Loss: 0.127||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1940||Train Loss: 0.127||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1941||Train Loss: 0.129||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1942||Train Loss: 0.128||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1943||Train Loss: 0.126||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1944||Train Loss: 0.127||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1945||Train Loss: 0.128||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1946||Train Loss: 0.129||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1947||Train Loss: 0.128||Val Loss: 0.133||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1948||Train Loss: 0.126||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1949||Train Loss: 0.128||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1950||Train Loss: 0.128||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1951||Train Loss: 0.128||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1952||Train Loss: 0.128||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1953||Train Loss: 0.128||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1954||Train Loss: 0.127||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1955||Train Loss: 0.127||Val Loss: 0.134||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1956||Train Loss: 0.127||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1957||Train Loss: 0.127||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1958||Train Loss: 0.127||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1959||Train Loss: 0.125||Val Loss: 0.143||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1960||Train Loss: 0.127||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1961||Train Loss: 0.128||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1962||Train Loss: 0.127||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1963||Train Loss: 0.126||Val Loss: 0.133||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1964||Train Loss: 0.128||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1965||Train Loss: 0.127||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1966||Train Loss: 0.126||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1967||Train Loss: 0.127||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1968||Train Loss: 0.128||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1969||Train Loss: 0.128||Val Loss: 0.141||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1970||Train Loss: 0.126||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1971||Train Loss: 0.126||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1972||Train Loss: 0.126||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1973||Train Loss: 0.126||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1974||Train Loss: 0.125||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1975||Train Loss: 0.127||Val Loss: 0.145||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1976||Train Loss: 0.127||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1977||Train Loss: 0.126||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1978||Train Loss: 0.126||Val Loss: 0.138||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1979||Train Loss: 0.126||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1980||Train Loss: 0.125||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1981||Train Loss: 0.126||Val Loss: 0.140||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1982||Train Loss: 0.126||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1983||Train Loss: 0.126||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1984||Train Loss: 0.125||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1985||Train Loss: 0.127||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1986||Train Loss: 0.126||Val Loss: 0.133||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1987||Train Loss: 0.125||Val Loss: 0.134||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1988||Train Loss: 0.126||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1989||Train Loss: 0.124||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1990||Train Loss: 0.126||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1991||Train Loss: 0.126||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1992||Train Loss: 0.127||Val Loss: 0.133||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1993||Train Loss: 0.125||Val Loss: 0.137||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1994||Train Loss: 0.124||Val Loss: 0.132||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1995||Train Loss: 0.125||Val Loss: 0.134||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1996||Train Loss: 0.126||Val Loss: 0.135||Val AUC: 0.998||Val AP: 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1997||Train Loss: 0.125||Val Loss: 0.142||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1998||Train Loss: 0.125||Val Loss: 0.139||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 1999||Train Loss: 0.126||Val Loss: 0.136||Val AUC: 0.998||Val AP: 0.998\n",
      "Epoch: 2000||Train Loss: 0.125||Val Loss: 0.131||Val AUC: 0.998||Val AP: 0.998\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "n_save = 100\n",
    "\n",
    "results = {\n",
    "    'train_loss':[],\n",
    "    'val_loss':[],\n",
    "    'val_auc':[],\n",
    "    'val_ap':[]\n",
    "          }\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = train()\n",
    "    \n",
    "    val_loss, y_target, y_pred = evaluator(val_loader)\n",
    "    val_auc = roc_auc_score(y_target, y_pred)\n",
    "    val_ap = average_precision_score(y_target, y_pred)\n",
    "    \n",
    "    results['train_loss'].append(train_loss)\n",
    "    results['val_loss'].append(val_loss)\n",
    "    results['val_auc'].append(val_auc)\n",
    "    results['val_ap'].append(val_ap)\n",
    "    \n",
    "    if (epoch % n_save) == 0:\n",
    "        torch.save(model.state_dict(), 'weights/link_predictor_epoch_' + str(epoch))\n",
    "    \n",
    "    print('Epoch: %i||Train Loss: %.3f||Val Loss: %.3f||Val AUC: %.3f||Val AP: %.3f' %(epoch, train_loss, val_loss, val_auc, val_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. The train loss is the average throughout the entire epoch, whereas the test loss is computed after a single training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lw = 2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].text(-0.1, 1.05, '(a)', transform=axes[0].transAxes, size=15)\n",
    "axes[1].text(-0.1, 1.05, '(b)', transform=axes[1].transAxes, size=15)\n",
    "\n",
    "axes[0].plot(results['train_loss'], label='train', linewidth=lw)\n",
    "axes[0].plot(results['val_loss'], label='val', linewidth=lw)\n",
    "axes[0].set_xlabel('epochs')\n",
    "axes[0].set_ylabel('reconstruction loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(results['val_auc'], label='AUC', linewidth=lw)\n",
    "axes[1].plot(results['val_ap'], label='AP', linewidth=lw)\n",
    "axes[1].set_xlabel('epochs')\n",
    "axes[1].legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('figures/link_prediction_trainresults.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].text(-0.1, 1.05, '(a)', transform=axes[0].transAxes, size=15)\n",
    "axes[1].text(-0.1, 1.05, '(b)', transform=axes[1].transAxes, size=15)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_target, y_pred)\n",
    "axes[0].plot(fpr, tpr, lw=lw, label='AUC = %0.2f' % results['val_auc'][-1])\n",
    "axes[0].plot([0, 1], [0, 1], color='k', lw=lw, linestyle='--')\n",
    "axes[0].set_xlim([-0.01, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.01])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "kwargs = dict(histtype='stepfilled', alpha=0.9, density=True, bins=50, edgecolor='k', linewidth=lw)\n",
    "axes[1].hist(y_pred, **kwargs)\n",
    "axes[1].set_xlabel('prediction probabilities')\n",
    "axes[1].set_ylabel('density')\n",
    "axes[1].set_xlim([0,1])\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('figures/link_prediction_testresults.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5926835"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the validation set to pick the model with the lowest test loss and then load from that checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch = np.argmin(np.asarray(results['val_loss']))\n",
    "best_epoch = int(math.ceil(best_epoch / 100.0)) * 100\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(num_node_features=data.x.shape[1], hidden_channels=256, embed_dim=64).to(device)\n",
    "model.load_state_dict(torch.load('weights/link_predictor_epoch_' + str(best_epoch)))\n",
    "model.eval()\n",
    "model.set_aggr('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c462cd6725c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_ap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Loss: %.3f|Test ACC: %.2f||Test AUC: %.3f||Test AP: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "test_loss, y_target, y_pred = evaluator(test_loader)\n",
    "test_auc = roc_auc_score(y_target, y_pred)\n",
    "test_ap = average_precision_score(y_target, y_pred)\n",
    "test_acc = np.mean(y_target == (y_pred > 0.5))\n",
    "print('Test Loss: %.3f|Test ACC: %.2f||Test AUC: %.3f||Test AP: %.3f' %(test_loss, test_acc, test_auc, test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].text(-0.1, 1.05, '(a)', transform=axes[0].transAxes, size=15)\n",
    "axes[1].text(-0.1, 1.05, '(b)', transform=axes[1].transAxes, size=15)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_target, y_pred)\n",
    "axes[0].plot(fpr, tpr, lw=lw, label='AUC = %0.2f' % test_auc)\n",
    "axes[0].plot([0, 1], [0, 1], color='k', lw=lw, linestyle='--')\n",
    "axes[0].set_xlim([-0.01, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.01])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "kwargs = dict(histtype='stepfilled', alpha=0.9, density=True, bins=50, edgecolor='k', linewidth=lw)\n",
    "axes[1].hist(y_pred, **kwargs)\n",
    "axes[1].set_xlabel('prediction probabilities')\n",
    "axes[1].set_ylabel('density')\n",
    "axes[1].set_xlim([0,1])\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('figures/link_prediction_testresults.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch geometric)",
   "language": "python",
   "name": "pygeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
